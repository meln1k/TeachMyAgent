<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>TeachMyAgent.students.test_policy API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<link rel="icon" href="https://github.com/flowersteam/TeachMyAgent/blob/gh-pages/images/favicon-96x96.png?raw=true" />
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>TeachMyAgent.students.test_policy</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import json
import os
from os import listdir
import os.path as osp
import pickle
import time
from collections import OrderedDict, Counter
import argparse
import numpy as np
import pathlib
import joblib

from gym.wrappers.monitoring.video_recorder import VideoRecorder

from TeachMyAgent.run_utils.environment_args_handler import EnvironmentArgsHandler
from TeachMyAgent.run_utils.student_args_handler import StudentArgsHandler
from TeachMyAgent.teachers.teacher_controller import param_vec_to_param_dict

from TeachMyAgent.students.spinup.utils.test_policy import load_policy_and_env as spinup_load_policy
from TeachMyAgent.students.openai_baselines.ppo2.ppo2 import get_model as get_baselines_model
from TeachMyAgent.students.ppo_utils import create_custom_vec_normalized_envs

def get_student_type(save_path):
    &#39;&#39;&#39;
        Returns &#39;spinup&#39; or &#39;baselines&#39; depending on how the logs look like.

        Args:
            save_path (str): Path containing logs
    &#39;&#39;&#39;
    for root, _, files in os.walk(save_path):
        if &#39;progress.txt&#39; in files: # Spinup
            return &#39;spinup&#39;
        elif &#39;progress.csv&#39; in files: # OpenAI Baselines
            return &#39;baselines&#39;

def load_training_infos(save_path):
    &#39;&#39;&#39;
        Load hyperparameters stored in config.json.

        Args:
            save_path (str): Path containing logs
    &#39;&#39;&#39;
    with open(osp.join(save_path, &#39;config.json&#39;)) as json_file:
        training_config = json.load(json_file)
    return training_config

def get_baselines_last_checkpoint(path):
    &#39;&#39;&#39;
        OpenAI Baselines students save multiple checkpoints of the model. This function only loads the last one.

        Args:
            save_path (str): Path containing checkpoints
    &#39;&#39;&#39;
    last_checkpoint = -1
    for f in listdir(path):
        if osp.isfile(osp.join(path, f)):
            try:
                checkpoint = int(f)
                last_checkpoint = f if checkpoint &gt; int(last_checkpoint) else last_checkpoint
            except Exception:
                continue
    return last_checkpoint

def load_env_params(save_path):
    &#39;&#39;&#39;
        Load book-keeped information (e.g. training and test tasks along with the obtained reward).

        Args:
            save_path (str): Path containing logs
    &#39;&#39;&#39;
    with open(osp.join(save_path, &#39;env_params_save.pkl&#39;), &#34;rb&#34;) as file:
        teacher_dict = pickle.load(file)
    return teacher_dict

def get_training_test_size(teacher_dict):
    &#39;&#39;&#39;
        Calculate size of test set used during training.

        Args:
            teacher_dict (dict): Dictionary of loaded logs.
    &#39;&#39;&#39;
    param_to_count = teacher_dict[&#34;env_params_test&#34;][0]
    nb_of_epochs = 0
    for param in teacher_dict[&#34;env_params_test&#34;]:
        if (param_to_count == param).all():
            nb_of_epochs += 1

    return int(len(teacher_dict[&#34;env_params_test&#34;]) / nb_of_epochs)

def load_training_test_set(save_path, order_by_best_rewards=None):
    &#39;&#39;&#39;
        Load test set used during training.

        Args:
            save_path (str): Path containing logs
            order_by_best_rewards (str): If None =&gt; Do not order test set.
                                   If True =&gt; Order test set using rewards obtained from greatest to lowest
                                   If False =&gt; Order test set using rewards obtained from lowest to greatest

        Returns:
            list of tasks and list associated rewards
    &#39;&#39;&#39;
    ### Get last training test episodes and sort them by total reward
    teacher_dict = load_env_params(save_path)
    test_set_size = get_training_test_size(teacher_dict)

    test_params_to_use = teacher_dict[&#34;env_params_test&#34;][-test_set_size:]  # nth last
    test_rewards_to_use = teacher_dict[&#34;env_test_rewards&#34;][-test_set_size:]
    if order_by_best_rewards is not None:
        print(&#34;Getting test set tasks ordered by last return from {} to {} ...&#34;
              .format(&#34;greatest&#34; if order_by_best_rewards else &#34;lowest&#34;,
                      &#34;lowest&#34; if order_by_best_rewards else &#34;greatest&#34;))
        sorted_indexes_of_test_episodes = sorted(range(test_set_size),
                                                 key=lambda k: test_rewards_to_use[k],
                                                 reverse=order_by_best_rewards)  # Sort with best results first
    else:
        print(&#34;Getting test set tasks as defined...&#34;)
        sorted_indexes_of_test_episodes = range(test_set_size)

    teacher_param_env_bounds = OrderedDict(teacher_dict[&#34;env_param_bounds&#34;])
    env_params_list = [param_vec_to_param_dict(teacher_param_env_bounds, test_params_to_use[i])
                       for i in sorted_indexes_of_test_episodes]
    associated_rewards_list = [test_rewards_to_use[i] for i in sorted_indexes_of_test_episodes]
    return env_params_list, associated_rewards_list

def load_fixed_test_set(save_path, test_set_name):
    &#39;&#39;&#39;
        Load a test set from a file.

        Args:
            save_path (str): Path containing test sets
            test_set_name (str): Name of the file containing the test set (do not add the extension)

        Returns:
            list of tasks
    &#39;&#39;&#39;
    teacher_dict = load_env_params(save_path)
    teacher_param_env_bounds = OrderedDict(teacher_dict[&#34;env_param_bounds&#34;])
    test_param_vec = np.array(pickle.load(open(&#34;TeachMyAgent/teachers/test_sets/&#34; + test_set_name + &#34;.pkl&#34;, &#34;rb&#34;)))

    return [param_vec_to_param_dict(teacher_param_env_bounds, vec) for vec in test_param_vec]

def load_env(save_path, load_test_env=False):
    &#39;&#39;&#39;
        Load saved environment.

        Args:
            save_path (str): Path containing logs
            load_test_env (str): Name of the file containing the test set (do not add the extension)

        Returns:
            loaded environment
    &#39;&#39;&#39;
    try:
        filename = osp.join(save_path, &#39;vars.pkl&#39;)
        state = joblib.load(filename)
        if load_test_env:
            env = state[&#39;test_env&#39;]
        else:
            env = state[&#39;env&#39;]
    except Exception as err:
        print(&#34;Unable to load envs : {}&#34;.format(err))
        env = None

    return env

def load_vectorized_env(save_path, env):
    try:
        filename = osp.join(save_path, &#39;vars.pkl&#39;)
        state = joblib.load(filename)
        env.__load_rms__(state[&#34;ob_rms&#34;], state[&#34;ret_rms&#34;])
    except Exception as err:
        print(&#34;Unable to load Running Mean Stds : {}&#34;.format(err))

def run_policy(env, get_action, env_params_list, max_ep_len=None, episode_id=0, record=False, recording_path=None,
               no_render=False, use_baselines=False):
    &#39;&#39;&#39;
        Run an episode of a trained policy.

        Args:
            env: Environment
            get_action: Policy function
            env_params_list: List of tasks among one must be loaded
            max_ep_len: Maximum number of steps allowed in the episode
            episode_id: Id of the episode to load in `env_params_list`
            record: Whether a video of the episode should be recorded
            recording_path: Path on which the video must be saved
            no_render: Whether the episode must be ran without a frame rendering it
            use_baselines: Whether the policy was trained using OpenAI Baselines
    &#39;&#39;&#39;
    if record:
        if os.name == &#34;nt&#34;:
            full_path = os.path.join(pathlib.Path().absolute(), recording_path)
            full_path_len = len(full_path)
            nb_char_to_remove = full_path_len - 245
            if nb_char_to_remove &gt; 0:
                recording_path = recording_path[:-nb_char_to_remove]
        video_recorder = VideoRecorder(env, recording_path + &#34;_ep&#34; + str(episode_id) + &#34;.mp4&#34;, enabled=True)

    if use_baselines:
        env.get_raw_env().set_environment(**env_params_list[episode_id])
    else:
        env.set_environment(**env_params_list[episode_id])

    if use_baselines:
        _, o = env.reset()
    else:
        o = env.reset()

    r, d, ep_ret, ep_len, n = 0, False, 0, 0, 0
    while True:
        if record and video_recorder.enabled:
            video_recorder.capture_frame()
        if not record and not no_render:
            env.render()
            time.sleep(1e-3)

        a = get_action(o)
        o, r, d, i = env.step(a)
        if use_baselines:
            ep_ret += i[0][&#34;original_reward&#34;][0]
        else:
            ep_ret += r
        ep_len += 1

        if d or (ep_len == max_ep_len):
            print(&#39;Episode %d \t EpRet %.3f \t EpLen %d&#39;%(episode_id, ep_ret, ep_len))
            if record and video_recorder.enabled:
                video_recorder.close()
                video_recorder.enabled = False
            break
    return ep_ret

def main(args):
    &#39;&#39;&#39;
        Test a learned policy on tasks.

        Args:
            args: arguments defining what has to be run
    &#39;&#39;&#39;
    if args.fixed_test_set is None:
        # training_config = load_training_infos(args.fpath)
        # nb_test_episodes_during_training = training_config[&#34;num_test_episodes&#34;] \
        #     if &#34;num_test_episodes&#34; in training_config \
        #     else training_config[&#34;nb_test_episodes&#34;]
        test_set_params, _ = load_training_test_set(args.fpath, args.bests)
    else:
        test_set_params = load_fixed_test_set(args.fpath, args.fixed_test_set)

    os.environ[&#34;CUDA_VISIBLE_DEVICES&#34;] = &#34;-1&#34;
    student_type = get_student_type(args.fpath)

    env = None
    if args.load_env:
        env = load_env(args.fpath, args.use_test_env is not None)

    if env is None:
        env_fn, _, _, _ = EnvironmentArgsHandler.get_object_from_arguments(args)
        if student_type == &#34;spinup&#34;:
            env = env_fn()
        elif student_type == &#34;baselines&#34;:
            env, _ = create_custom_vec_normalized_envs(env_fn)
            load_vectorized_env(args.fpath, env)

    if student_type == &#39;spinup&#39;:
        get_action = spinup_load_policy(args.fpath,
                                        args.itr if args.itr &gt;= 0 else &#39;last&#39;,
                                        args.deterministic)
        env._SET_RENDERING_VIEWPORT_SIZE(600, 400)
    elif student_type == &#39;baselines&#39;:
        ac_kwargs = dict()
        ac_kwargs[&#39;hidden_sizes&#39;] = [int(layer) for layer in args.hidden_sizes.split(&#34;/&#34;)]
        nbatch_train = args.nb_env_steps * 1e6 // int(args.sample_size//args.batch_size)

        model = get_baselines_model(network=args.network, nbatch_train=nbatch_train, ob_space=env.observation_space,
                                    ac_space=env.action_space, env=env, nsteps=args.sample_size, ent_coef=args.ent_coef,
                                    vf_coef=args.vf_coef, hidden_sizes=ac_kwargs[&#39;hidden_sizes&#39;])
        last_checkpoint = get_baselines_last_checkpoint(args.fpath + &#34;/checkpoints/&#34;)
        model.load(args.fpath + &#34;/checkpoints/&#34; + last_checkpoint)
        # Careful : The recurrent version is not implemented here yet
        get_action = lambda o: model.step(o)[0]
        env.get_raw_env()._SET_RENDERING_VIEWPORT_SIZE(600, 400)
    else:
        raise Exception(&#39;Unknown student type.&#39;)

    if args.episode_ids == &#34;-1&#34;:
        print(&#34;Testing the policy on the whole test set...&#34;)
        episodes = [i for i in range(len(test_set_params))]
    else:
        episodes = [int(id) for id in args.episode_ids.split(&#34;/&#34;)]

    rewards = []
    for episode_id in episodes:
        r = run_policy(env, get_action, test_set_params, args.len, episode_id, args.record, args.recording_path,
                       args.norender, use_baselines=student_type == &#39;baselines&#39;)
        rewards.append(r)
    env.close()
    return rewards

def str2bool(v):
    if isinstance(v, bool):
       return v
    if v.lower() in (&#39;yes&#39;, &#39;true&#39;, &#39;t&#39;, &#39;y&#39;, &#39;1&#39;):
        return True
    elif v.lower() in (&#39;no&#39;, &#39;false&#39;, &#39;f&#39;, &#39;n&#39;, &#39;0&#39;):
        return False
    else:
        raise argparse.ArgumentTypeError(&#39;Boolean value expected.&#39;)

def get_parser():
    &#39;&#39;&#39;
        Define arguments that can be used when testing a policy.
    &#39;&#39;&#39;
    parser = argparse.ArgumentParser()
    parser.add_argument(&#39;--fpath&#39;, type=str)
    parser.add_argument(&#39;--len&#39;, &#39;-l&#39;, type=int, default=0)
    parser.add_argument(&#39;--norender&#39;, &#39;-nr&#39;, action=&#39;store_true&#39;)
    parser.add_argument(&#39;--itr&#39;, &#39;-i&#39;, type=int, default=-1)
    parser.add_argument(&#39;--deterministic&#39;, &#39;-d&#39;, action=&#39;store_true&#39;)
    parser.add_argument(&#39;--episode_ids&#39;, &#39;-id&#39;, type=str, default=&#34;0&#34;)
    parser.add_argument(&#39;--bests&#39;, type=str2bool, default=None)
    parser.add_argument(&#39;--fixed_test_set&#39;, &#39;-ts&#39;, type=str, default=None)
    parser.add_argument(&#39;--load_env&#39;, action=&#39;store_true&#39;)
    parser.add_argument(&#39;--use_test_env&#39;, action=&#39;store_true&#39;)

    parser.add_argument(&#39;--record&#39;, type=str2bool, default=False)
    parser.add_argument(&#39;--recording_path&#39;, type=str, default=None)
    EnvironmentArgsHandler.set_parser_arguments(parser)
    StudentArgsHandler.set_parser_arguments(parser)

    return parser

if __name__ == &#39;__main__&#39;:
    parser = get_parser()
    args = parser.parse_args()
    main(args)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="TeachMyAgent.students.test_policy.get_baselines_last_checkpoint"><code class="name flex">
<span>def <span class="ident">get_baselines_last_checkpoint</span></span>(<span>path)</span>
</code></dt>
<dd>
<div class="desc"><p>OpenAI Baselines students save multiple checkpoints of the model. This function only loads the last one.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>save_path</code></strong> :&ensp;<code>str</code></dt>
<dd>Path containing checkpoints</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_baselines_last_checkpoint(path):
    &#39;&#39;&#39;
        OpenAI Baselines students save multiple checkpoints of the model. This function only loads the last one.

        Args:
            save_path (str): Path containing checkpoints
    &#39;&#39;&#39;
    last_checkpoint = -1
    for f in listdir(path):
        if osp.isfile(osp.join(path, f)):
            try:
                checkpoint = int(f)
                last_checkpoint = f if checkpoint &gt; int(last_checkpoint) else last_checkpoint
            except Exception:
                continue
    return last_checkpoint</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.test_policy.get_parser"><code class="name flex">
<span>def <span class="ident">get_parser</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Define arguments that can be used when testing a policy.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_parser():
    &#39;&#39;&#39;
        Define arguments that can be used when testing a policy.
    &#39;&#39;&#39;
    parser = argparse.ArgumentParser()
    parser.add_argument(&#39;--fpath&#39;, type=str)
    parser.add_argument(&#39;--len&#39;, &#39;-l&#39;, type=int, default=0)
    parser.add_argument(&#39;--norender&#39;, &#39;-nr&#39;, action=&#39;store_true&#39;)
    parser.add_argument(&#39;--itr&#39;, &#39;-i&#39;, type=int, default=-1)
    parser.add_argument(&#39;--deterministic&#39;, &#39;-d&#39;, action=&#39;store_true&#39;)
    parser.add_argument(&#39;--episode_ids&#39;, &#39;-id&#39;, type=str, default=&#34;0&#34;)
    parser.add_argument(&#39;--bests&#39;, type=str2bool, default=None)
    parser.add_argument(&#39;--fixed_test_set&#39;, &#39;-ts&#39;, type=str, default=None)
    parser.add_argument(&#39;--load_env&#39;, action=&#39;store_true&#39;)
    parser.add_argument(&#39;--use_test_env&#39;, action=&#39;store_true&#39;)

    parser.add_argument(&#39;--record&#39;, type=str2bool, default=False)
    parser.add_argument(&#39;--recording_path&#39;, type=str, default=None)
    EnvironmentArgsHandler.set_parser_arguments(parser)
    StudentArgsHandler.set_parser_arguments(parser)

    return parser</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.test_policy.get_student_type"><code class="name flex">
<span>def <span class="ident">get_student_type</span></span>(<span>save_path)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns 'spinup' or 'baselines' depending on how the logs look like.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>save_path</code></strong> :&ensp;<code>str</code></dt>
<dd>Path containing logs</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_student_type(save_path):
    &#39;&#39;&#39;
        Returns &#39;spinup&#39; or &#39;baselines&#39; depending on how the logs look like.

        Args:
            save_path (str): Path containing logs
    &#39;&#39;&#39;
    for root, _, files in os.walk(save_path):
        if &#39;progress.txt&#39; in files: # Spinup
            return &#39;spinup&#39;
        elif &#39;progress.csv&#39; in files: # OpenAI Baselines
            return &#39;baselines&#39;</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.test_policy.get_training_test_size"><code class="name flex">
<span>def <span class="ident">get_training_test_size</span></span>(<span>teacher_dict)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate size of test set used during training.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>teacher_dict</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary of loaded logs.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_training_test_size(teacher_dict):
    &#39;&#39;&#39;
        Calculate size of test set used during training.

        Args:
            teacher_dict (dict): Dictionary of loaded logs.
    &#39;&#39;&#39;
    param_to_count = teacher_dict[&#34;env_params_test&#34;][0]
    nb_of_epochs = 0
    for param in teacher_dict[&#34;env_params_test&#34;]:
        if (param_to_count == param).all():
            nb_of_epochs += 1

    return int(len(teacher_dict[&#34;env_params_test&#34;]) / nb_of_epochs)</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.test_policy.load_env"><code class="name flex">
<span>def <span class="ident">load_env</span></span>(<span>save_path, load_test_env=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Load saved environment.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>save_path</code></strong> :&ensp;<code>str</code></dt>
<dd>Path containing logs</dd>
<dt><strong><code>load_test_env</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the file containing the test set (do not add the extension)</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>loaded environment</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_env(save_path, load_test_env=False):
    &#39;&#39;&#39;
        Load saved environment.

        Args:
            save_path (str): Path containing logs
            load_test_env (str): Name of the file containing the test set (do not add the extension)

        Returns:
            loaded environment
    &#39;&#39;&#39;
    try:
        filename = osp.join(save_path, &#39;vars.pkl&#39;)
        state = joblib.load(filename)
        if load_test_env:
            env = state[&#39;test_env&#39;]
        else:
            env = state[&#39;env&#39;]
    except Exception as err:
        print(&#34;Unable to load envs : {}&#34;.format(err))
        env = None

    return env</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.test_policy.load_env_params"><code class="name flex">
<span>def <span class="ident">load_env_params</span></span>(<span>save_path)</span>
</code></dt>
<dd>
<div class="desc"><p>Load book-keeped information (e.g. training and test tasks along with the obtained reward).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>save_path</code></strong> :&ensp;<code>str</code></dt>
<dd>Path containing logs</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_env_params(save_path):
    &#39;&#39;&#39;
        Load book-keeped information (e.g. training and test tasks along with the obtained reward).

        Args:
            save_path (str): Path containing logs
    &#39;&#39;&#39;
    with open(osp.join(save_path, &#39;env_params_save.pkl&#39;), &#34;rb&#34;) as file:
        teacher_dict = pickle.load(file)
    return teacher_dict</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.test_policy.load_fixed_test_set"><code class="name flex">
<span>def <span class="ident">load_fixed_test_set</span></span>(<span>save_path, test_set_name)</span>
</code></dt>
<dd>
<div class="desc"><p>Load a test set from a file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>save_path</code></strong> :&ensp;<code>str</code></dt>
<dd>Path containing test sets</dd>
<dt><strong><code>test_set_name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the file containing the test set (do not add the extension)</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>list of tasks</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_fixed_test_set(save_path, test_set_name):
    &#39;&#39;&#39;
        Load a test set from a file.

        Args:
            save_path (str): Path containing test sets
            test_set_name (str): Name of the file containing the test set (do not add the extension)

        Returns:
            list of tasks
    &#39;&#39;&#39;
    teacher_dict = load_env_params(save_path)
    teacher_param_env_bounds = OrderedDict(teacher_dict[&#34;env_param_bounds&#34;])
    test_param_vec = np.array(pickle.load(open(&#34;TeachMyAgent/teachers/test_sets/&#34; + test_set_name + &#34;.pkl&#34;, &#34;rb&#34;)))

    return [param_vec_to_param_dict(teacher_param_env_bounds, vec) for vec in test_param_vec]</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.test_policy.load_training_infos"><code class="name flex">
<span>def <span class="ident">load_training_infos</span></span>(<span>save_path)</span>
</code></dt>
<dd>
<div class="desc"><p>Load hyperparameters stored in config.json.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>save_path</code></strong> :&ensp;<code>str</code></dt>
<dd>Path containing logs</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_training_infos(save_path):
    &#39;&#39;&#39;
        Load hyperparameters stored in config.json.

        Args:
            save_path (str): Path containing logs
    &#39;&#39;&#39;
    with open(osp.join(save_path, &#39;config.json&#39;)) as json_file:
        training_config = json.load(json_file)
    return training_config</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.test_policy.load_training_test_set"><code class="name flex">
<span>def <span class="ident">load_training_test_set</span></span>(<span>save_path, order_by_best_rewards=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Load test set used during training.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>save_path</code></strong> :&ensp;<code>str</code></dt>
<dd>Path containing logs</dd>
<dt><strong><code>order_by_best_rewards</code></strong> :&ensp;<code>str</code></dt>
<dd>If None =&gt; Do not order test set.
If True =&gt; Order test set using rewards obtained from greatest to lowest
If False =&gt; Order test set using rewards obtained from lowest to greatest</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>list of tasks and list associated rewards</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_training_test_set(save_path, order_by_best_rewards=None):
    &#39;&#39;&#39;
        Load test set used during training.

        Args:
            save_path (str): Path containing logs
            order_by_best_rewards (str): If None =&gt; Do not order test set.
                                   If True =&gt; Order test set using rewards obtained from greatest to lowest
                                   If False =&gt; Order test set using rewards obtained from lowest to greatest

        Returns:
            list of tasks and list associated rewards
    &#39;&#39;&#39;
    ### Get last training test episodes and sort them by total reward
    teacher_dict = load_env_params(save_path)
    test_set_size = get_training_test_size(teacher_dict)

    test_params_to_use = teacher_dict[&#34;env_params_test&#34;][-test_set_size:]  # nth last
    test_rewards_to_use = teacher_dict[&#34;env_test_rewards&#34;][-test_set_size:]
    if order_by_best_rewards is not None:
        print(&#34;Getting test set tasks ordered by last return from {} to {} ...&#34;
              .format(&#34;greatest&#34; if order_by_best_rewards else &#34;lowest&#34;,
                      &#34;lowest&#34; if order_by_best_rewards else &#34;greatest&#34;))
        sorted_indexes_of_test_episodes = sorted(range(test_set_size),
                                                 key=lambda k: test_rewards_to_use[k],
                                                 reverse=order_by_best_rewards)  # Sort with best results first
    else:
        print(&#34;Getting test set tasks as defined...&#34;)
        sorted_indexes_of_test_episodes = range(test_set_size)

    teacher_param_env_bounds = OrderedDict(teacher_dict[&#34;env_param_bounds&#34;])
    env_params_list = [param_vec_to_param_dict(teacher_param_env_bounds, test_params_to_use[i])
                       for i in sorted_indexes_of_test_episodes]
    associated_rewards_list = [test_rewards_to_use[i] for i in sorted_indexes_of_test_episodes]
    return env_params_list, associated_rewards_list</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.test_policy.load_vectorized_env"><code class="name flex">
<span>def <span class="ident">load_vectorized_env</span></span>(<span>save_path, env)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_vectorized_env(save_path, env):
    try:
        filename = osp.join(save_path, &#39;vars.pkl&#39;)
        state = joblib.load(filename)
        env.__load_rms__(state[&#34;ob_rms&#34;], state[&#34;ret_rms&#34;])
    except Exception as err:
        print(&#34;Unable to load Running Mean Stds : {}&#34;.format(err))</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.test_policy.main"><code class="name flex">
<span>def <span class="ident">main</span></span>(<span>args)</span>
</code></dt>
<dd>
<div class="desc"><p>Test a learned policy on tasks.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>args</code></strong></dt>
<dd>arguments defining what has to be run</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def main(args):
    &#39;&#39;&#39;
        Test a learned policy on tasks.

        Args:
            args: arguments defining what has to be run
    &#39;&#39;&#39;
    if args.fixed_test_set is None:
        # training_config = load_training_infos(args.fpath)
        # nb_test_episodes_during_training = training_config[&#34;num_test_episodes&#34;] \
        #     if &#34;num_test_episodes&#34; in training_config \
        #     else training_config[&#34;nb_test_episodes&#34;]
        test_set_params, _ = load_training_test_set(args.fpath, args.bests)
    else:
        test_set_params = load_fixed_test_set(args.fpath, args.fixed_test_set)

    os.environ[&#34;CUDA_VISIBLE_DEVICES&#34;] = &#34;-1&#34;
    student_type = get_student_type(args.fpath)

    env = None
    if args.load_env:
        env = load_env(args.fpath, args.use_test_env is not None)

    if env is None:
        env_fn, _, _, _ = EnvironmentArgsHandler.get_object_from_arguments(args)
        if student_type == &#34;spinup&#34;:
            env = env_fn()
        elif student_type == &#34;baselines&#34;:
            env, _ = create_custom_vec_normalized_envs(env_fn)
            load_vectorized_env(args.fpath, env)

    if student_type == &#39;spinup&#39;:
        get_action = spinup_load_policy(args.fpath,
                                        args.itr if args.itr &gt;= 0 else &#39;last&#39;,
                                        args.deterministic)
        env._SET_RENDERING_VIEWPORT_SIZE(600, 400)
    elif student_type == &#39;baselines&#39;:
        ac_kwargs = dict()
        ac_kwargs[&#39;hidden_sizes&#39;] = [int(layer) for layer in args.hidden_sizes.split(&#34;/&#34;)]
        nbatch_train = args.nb_env_steps * 1e6 // int(args.sample_size//args.batch_size)

        model = get_baselines_model(network=args.network, nbatch_train=nbatch_train, ob_space=env.observation_space,
                                    ac_space=env.action_space, env=env, nsteps=args.sample_size, ent_coef=args.ent_coef,
                                    vf_coef=args.vf_coef, hidden_sizes=ac_kwargs[&#39;hidden_sizes&#39;])
        last_checkpoint = get_baselines_last_checkpoint(args.fpath + &#34;/checkpoints/&#34;)
        model.load(args.fpath + &#34;/checkpoints/&#34; + last_checkpoint)
        # Careful : The recurrent version is not implemented here yet
        get_action = lambda o: model.step(o)[0]
        env.get_raw_env()._SET_RENDERING_VIEWPORT_SIZE(600, 400)
    else:
        raise Exception(&#39;Unknown student type.&#39;)

    if args.episode_ids == &#34;-1&#34;:
        print(&#34;Testing the policy on the whole test set...&#34;)
        episodes = [i for i in range(len(test_set_params))]
    else:
        episodes = [int(id) for id in args.episode_ids.split(&#34;/&#34;)]

    rewards = []
    for episode_id in episodes:
        r = run_policy(env, get_action, test_set_params, args.len, episode_id, args.record, args.recording_path,
                       args.norender, use_baselines=student_type == &#39;baselines&#39;)
        rewards.append(r)
    env.close()
    return rewards</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.test_policy.run_policy"><code class="name flex">
<span>def <span class="ident">run_policy</span></span>(<span>env, get_action, env_params_list, max_ep_len=None, episode_id=0, record=False, recording_path=None, no_render=False, use_baselines=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Run an episode of a trained policy.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>env</code></strong></dt>
<dd>Environment</dd>
<dt><strong><code>get_action</code></strong></dt>
<dd>Policy function</dd>
<dt><strong><code>env_params_list</code></strong></dt>
<dd>List of tasks among one must be loaded</dd>
<dt><strong><code>max_ep_len</code></strong></dt>
<dd>Maximum number of steps allowed in the episode</dd>
<dt><strong><code>episode_id</code></strong></dt>
<dd>Id of the episode to load in <code>env_params_list</code></dd>
<dt><strong><code>record</code></strong></dt>
<dd>Whether a video of the episode should be recorded</dd>
<dt><strong><code>recording_path</code></strong></dt>
<dd>Path on which the video must be saved</dd>
<dt><strong><code>no_render</code></strong></dt>
<dd>Whether the episode must be ran without a frame rendering it</dd>
<dt><strong><code>use_baselines</code></strong></dt>
<dd>Whether the policy was trained using OpenAI Baselines</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_policy(env, get_action, env_params_list, max_ep_len=None, episode_id=0, record=False, recording_path=None,
               no_render=False, use_baselines=False):
    &#39;&#39;&#39;
        Run an episode of a trained policy.

        Args:
            env: Environment
            get_action: Policy function
            env_params_list: List of tasks among one must be loaded
            max_ep_len: Maximum number of steps allowed in the episode
            episode_id: Id of the episode to load in `env_params_list`
            record: Whether a video of the episode should be recorded
            recording_path: Path on which the video must be saved
            no_render: Whether the episode must be ran without a frame rendering it
            use_baselines: Whether the policy was trained using OpenAI Baselines
    &#39;&#39;&#39;
    if record:
        if os.name == &#34;nt&#34;:
            full_path = os.path.join(pathlib.Path().absolute(), recording_path)
            full_path_len = len(full_path)
            nb_char_to_remove = full_path_len - 245
            if nb_char_to_remove &gt; 0:
                recording_path = recording_path[:-nb_char_to_remove]
        video_recorder = VideoRecorder(env, recording_path + &#34;_ep&#34; + str(episode_id) + &#34;.mp4&#34;, enabled=True)

    if use_baselines:
        env.get_raw_env().set_environment(**env_params_list[episode_id])
    else:
        env.set_environment(**env_params_list[episode_id])

    if use_baselines:
        _, o = env.reset()
    else:
        o = env.reset()

    r, d, ep_ret, ep_len, n = 0, False, 0, 0, 0
    while True:
        if record and video_recorder.enabled:
            video_recorder.capture_frame()
        if not record and not no_render:
            env.render()
            time.sleep(1e-3)

        a = get_action(o)
        o, r, d, i = env.step(a)
        if use_baselines:
            ep_ret += i[0][&#34;original_reward&#34;][0]
        else:
            ep_ret += r
        ep_len += 1

        if d or (ep_len == max_ep_len):
            print(&#39;Episode %d \t EpRet %.3f \t EpLen %d&#39;%(episode_id, ep_ret, ep_len))
            if record and video_recorder.enabled:
                video_recorder.close()
                video_recorder.enabled = False
            break
    return ep_ret</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.students.test_policy.str2bool"><code class="name flex">
<span>def <span class="ident">str2bool</span></span>(<span>v)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def str2bool(v):
    if isinstance(v, bool):
       return v
    if v.lower() in (&#39;yes&#39;, &#39;true&#39;, &#39;t&#39;, &#39;y&#39;, &#39;1&#39;):
        return True
    elif v.lower() in (&#39;no&#39;, &#39;false&#39;, &#39;f&#39;, &#39;n&#39;, &#39;0&#39;):
        return False
    else:
        raise argparse.ArgumentTypeError(&#39;Boolean value expected.&#39;)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<a href="http://developmentalsystems.org/TeachMyAgent/doc/">
<img src="https://github.com/flowersteam/TeachMyAgent/blob/gh-pages/images/home/head_image.png?raw=true" style="display: block; margin: 1em auto">
</a>
<a href="http://developmentalsystems.org/TeachMyAgent/doc/">Home</a> | <a href="http://developmentalsystems.org/TeachMyAgent/">Website</a>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="TeachMyAgent.students" href="index.html">TeachMyAgent.students</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="TeachMyAgent.students.test_policy.get_baselines_last_checkpoint" href="#TeachMyAgent.students.test_policy.get_baselines_last_checkpoint">get_baselines_last_checkpoint</a></code></li>
<li><code><a title="TeachMyAgent.students.test_policy.get_parser" href="#TeachMyAgent.students.test_policy.get_parser">get_parser</a></code></li>
<li><code><a title="TeachMyAgent.students.test_policy.get_student_type" href="#TeachMyAgent.students.test_policy.get_student_type">get_student_type</a></code></li>
<li><code><a title="TeachMyAgent.students.test_policy.get_training_test_size" href="#TeachMyAgent.students.test_policy.get_training_test_size">get_training_test_size</a></code></li>
<li><code><a title="TeachMyAgent.students.test_policy.load_env" href="#TeachMyAgent.students.test_policy.load_env">load_env</a></code></li>
<li><code><a title="TeachMyAgent.students.test_policy.load_env_params" href="#TeachMyAgent.students.test_policy.load_env_params">load_env_params</a></code></li>
<li><code><a title="TeachMyAgent.students.test_policy.load_fixed_test_set" href="#TeachMyAgent.students.test_policy.load_fixed_test_set">load_fixed_test_set</a></code></li>
<li><code><a title="TeachMyAgent.students.test_policy.load_training_infos" href="#TeachMyAgent.students.test_policy.load_training_infos">load_training_infos</a></code></li>
<li><code><a title="TeachMyAgent.students.test_policy.load_training_test_set" href="#TeachMyAgent.students.test_policy.load_training_test_set">load_training_test_set</a></code></li>
<li><code><a title="TeachMyAgent.students.test_policy.load_vectorized_env" href="#TeachMyAgent.students.test_policy.load_vectorized_env">load_vectorized_env</a></code></li>
<li><code><a title="TeachMyAgent.students.test_policy.main" href="#TeachMyAgent.students.test_policy.main">main</a></code></li>
<li><code><a title="TeachMyAgent.students.test_policy.run_policy" href="#TeachMyAgent.students.test_policy.run_policy">run_policy</a></code></li>
<li><code><a title="TeachMyAgent.students.test_policy.str2bool" href="#TeachMyAgent.students.test_policy.str2bool">str2bool</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>