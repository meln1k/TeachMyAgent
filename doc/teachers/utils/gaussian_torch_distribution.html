<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>TeachMyAgent.teachers.utils.gaussian_torch_distribution API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<link rel="icon" href="https://github.com/flowersteam/TeachMyAgent/blob/gh-pages/images/favicon-96x96.png?raw=true" />
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>TeachMyAgent.teachers.utils.gaussian_torch_distribution</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># Taken from https://github.com/psclklnk/spdl
# Copy of the license at TeachMyAgent/teachers/LICENSES/SPDL

import scipy.linalg as scpla
from abc import ABC
import numpy as np
import torch
import torch.nn as nn
from torch.distributions import MultivariateNormal
from TeachMyAgent.teachers.utils.torch import get_weights, set_weights, to_float_tensor
import copy


class AbstractDistribution(object):
    &#34;&#34;&#34;
    Interface for Distributions to represent a generic probability distribution.
    Probability distributions are often used by black box optimization
    algorithms in order to perform exploration in parameter space. In
    literature, they are also known as high level policies.

    &#34;&#34;&#34;

    def sample(self):
        &#34;&#34;&#34;
        Draw a sample from the distribution.

        Returns:
            A random vector sampled from the distribution.

        &#34;&#34;&#34;
        raise NotImplementedError

    def log_pdf(self, x):
        &#34;&#34;&#34;
        Compute the logarithm of the probability density function in the
        specified point

        Args:
            x (np.ndarray): the point where the log pdf is calculated

        Returns:
            The value of the log pdf in the specified point.

        &#34;&#34;&#34;
        raise NotImplementedError

    def __call__(self, x):
        &#34;&#34;&#34;
        Compute the probability density function in the specified point

        Args:
            x (np.ndarray): the point where the pdf is calculated

        Returns:
            The value of the pdf in the specified point.

        &#34;&#34;&#34;
        raise np.exp(self.log_pdf(x))


class Distribution(AbstractDistribution):
    &#34;&#34;&#34;
    Interface for Distributions to represent a generic probability distribution.
    Probability distributions are often used by black box optimization
    algorithms in order to perform exploration in parameter space. In
    literature, they are also known as high level policies.

    &#34;&#34;&#34;

    def mle(self, theta, weights=None):
        &#34;&#34;&#34;
        Compute the (weighted) maximum likelihood estimate of the points,
        and update the distribution accordingly.

        Args:
            theta (np.ndarray): a set of points, every row is a sample
            weights (np.ndarray, None): a vector of weights. If specified
                                        the weighted maximum likelihood
                                        estimate is computed instead of the
                                        plain maximum likelihood. The number of
                                        elements of this vector must be equal
                                        to the number of rows of the theta
                                        matrix.

        &#34;&#34;&#34;
        raise NotImplementedError

    def diff_log(self, theta):
        &#34;&#34;&#34;
        Compute the derivative of the gradient of the probability denstity
        function in the specified point.

        Args:
            theta (np.ndarray): the point where the gradient of the log pdf is calculated

        Returns:
            The gradient of the log pdf in the specified point.

        &#34;&#34;&#34;
        raise NotImplementedError

    def diff(self, theta):
        &#34;&#34;&#34;
        Compute the derivative of the probability density function, in the
        specified point. Normally it is computed w.r.t. the
        derivative of the logarithm of the probability density function,
        exploiting the likelihood ratio trick, i.e.:

        .. math::
            \\nabla_{\\rho}p(\\theta)=p(\\theta)\\nabla_{\\rho}\\log p(\\theta)

        Args:
            theta (np.ndarray): the point where the gradient of the pdf is
            calculated.

        Returns:
            The gradient of the pdf in the specified point.

        &#34;&#34;&#34;
        return self(theta) * self.diff_log(theta)

    def get_parameters(self):
        &#34;&#34;&#34;
        Getter.

        Returns:
             The current distribution parameters.

        &#34;&#34;&#34;
        raise NotImplementedError

    def set_parameters(self, rho):
        &#34;&#34;&#34;
        Setter.

        Args:
            rho (np.ndarray): the vector of the new parameters to be used by
                              the distribution

        &#34;&#34;&#34;
        raise NotImplementedError

    @property
    def parameters_size(self):
        &#34;&#34;&#34;
        Property.

        Returns:
             The size of the distribution parameters.

        &#34;&#34;&#34;
        raise NotImplementedError


class TorchDistribution(AbstractDistribution, ABC):
    &#34;&#34;&#34;
    Interface for a generic PyTorch distribution.
    A PyTorch distribution is a distribution implemented using PyTorch.
    Functions ending with &#39;_t&#39; use tensors as input, and also as output when
    required.

    &#34;&#34;&#34;

    def __init__(self, use_cuda):
        &#34;&#34;&#34;
        Constructor.

        Args:
            use_cuda (bool): whether to use cuda or not.

        &#34;&#34;&#34;
        self._use_cuda = use_cuda

    def entropy(self):
        &#34;&#34;&#34;
        Compute the entropy of the policy.

        Returns:
            The value of the entropy of the policy.

        &#34;&#34;&#34;

        return self.entropy_t().detach().cpu().numpy()

    def entropy_t(self):
        &#34;&#34;&#34;
        Compute the entropy of the policy.

        Returns:
            The tensor value of the entropy of the policy.

        &#34;&#34;&#34;
        raise NotImplementedError

    def mean(self):
        &#34;&#34;&#34;
        Compute the mean of the policy.

        Returns:
            The value of the mean of the policy.

        &#34;&#34;&#34;
        return self.mean_t().detach().cpu().numpy()

    def mean_t(self):
        &#34;&#34;&#34;
        Compute the mean of the policy.

        Returns:
            The tensor value of the mean of the policy.

        &#34;&#34;&#34;
        raise NotImplementedError

    def log_pdf(self, x):
        x = to_float_tensor(x, self._use_cuda)
        return self.log_pdf_t(x).detach().cpu().numpy()

    def log_pdf_t(self, x):
        &#34;&#34;&#34;
        Compute the logarithm of the probability density function in the
        specified point

        Args:
            x (torch.Tensor): the point where the log pdf is calculated

        Returns:
            The value of the log pdf in the specified point.

        &#34;&#34;&#34;
        raise NotImplementedError

    def set_weights(self, weights):
        &#34;&#34;&#34;
        Setter.

        Args:
            weights (np.ndarray): the vector of the new weights to be used by the distribution

        &#34;&#34;&#34;
        raise NotImplementedError

    def get_weights(self):
        &#34;&#34;&#34;
        Getter.

        Returns:
             The current policy weights.

        &#34;&#34;&#34;
        raise NotImplementedError

    def parameters(self):
        &#34;&#34;&#34;
        Returns the trainable distribution parameters, as expected by torch optimizers.

        Returns:
            List of parameters to be optimized.

        &#34;&#34;&#34;
        raise NotImplementedError

    def reset(self):
        pass

    @property
    def use_cuda(self):
        &#34;&#34;&#34;
        True if the policy is using cuda_tensors.
        &#34;&#34;&#34;
        return self._use_cuda


class GaussianTorchDistribution(TorchDistribution):

    def __init__(self, mu, chol_flat, use_cuda):
        super().__init__(use_cuda)
        self._dim = mu.shape[0]

        self._mu = nn.Parameter(torch.as_tensor(mu, dtype=torch.float32), requires_grad=True)
        self._chol_flat = nn.Parameter(torch.as_tensor(chol_flat, dtype=torch.float32), requires_grad=True)

        self.distribution_t = MultivariateNormal(self._mu, scale_tril=self.to_tril_matrix(self._chol_flat, self._dim))

    def __copy__(self):
        return GaussianTorchDistribution(self._mu, self._chol_flat, self.use_cuda)

    def __deepcopy__(self, memodict=None):
        return GaussianTorchDistribution(copy.deepcopy(self._mu), copy.deepcopy(self._chol_flat), self.use_cuda)

    @staticmethod
    def to_tril_matrix(chol_flat, dim):
        if isinstance(chol_flat, np.ndarray):
            chol = np.zeros((dim, dim))
            exp_fun = np.exp
        else:
            chol = torch.zeros((dim, dim))
            exp_fun = torch.exp

        d1, d2 = np.diag_indices(dim)
        chol[d1, d2] += exp_fun(chol_flat[0: dim])
        ld1, ld2 = np.tril_indices(dim, k=-1)
        chol[ld1, ld2] += chol_flat[dim:]

        return chol

    @staticmethod
    def flatten_matrix(mat, tril=False):
        if not tril:
            mat = scpla.cholesky(mat, lower=True)

        dim = mat.shape[0]
        d1, d2 = np.diag_indices(dim)
        ld1, ld2 = np.tril_indices(dim, k=-1)

        return np.concatenate((np.log(mat[d1, d2]), mat[ld1, ld2]))

    def entropy_t(self):
        return self.distribution_t.entropy()

    def mean_t(self):
        return self.distribution_t.mean

    def log_pdf_t(self, x):
        return self.distribution_t.log_prob(x)

    def sample(self):
        return self.distribution_t.rsample()

    def covariance_matrix(self):
        return self.distribution_t.covariance_matrix.detach().numpy()

    def set_weights(self, weights):
        set_weights([self._mu], weights[0:self._dim], self._use_cuda)
        set_weights([self._chol_flat], weights[self._dim:], self._use_cuda)
        # This is important - otherwise the changes will not be reflected!
        self.distribution_t = MultivariateNormal(self._mu, scale_tril=self.to_tril_matrix(self._chol_flat, self._dim))

    def get_weights(self):
        mu_weights = get_weights([self._mu])
        chol_flat_weights = get_weights([self._chol_flat])

        return np.concatenate([mu_weights, chol_flat_weights])

    def parameters(self):
        return [self._mu, self._chol_flat]</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution"><code class="flex name class">
<span>class <span class="ident">AbstractDistribution</span></span>
</code></dt>
<dd>
<div class="desc"><p>Interface for Distributions to represent a generic probability distribution.
Probability distributions are often used by black box optimization
algorithms in order to perform exploration in parameter space. In
literature, they are also known as high level policies.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AbstractDistribution(object):
    &#34;&#34;&#34;
    Interface for Distributions to represent a generic probability distribution.
    Probability distributions are often used by black box optimization
    algorithms in order to perform exploration in parameter space. In
    literature, they are also known as high level policies.

    &#34;&#34;&#34;

    def sample(self):
        &#34;&#34;&#34;
        Draw a sample from the distribution.

        Returns:
            A random vector sampled from the distribution.

        &#34;&#34;&#34;
        raise NotImplementedError

    def log_pdf(self, x):
        &#34;&#34;&#34;
        Compute the logarithm of the probability density function in the
        specified point

        Args:
            x (np.ndarray): the point where the log pdf is calculated

        Returns:
            The value of the log pdf in the specified point.

        &#34;&#34;&#34;
        raise NotImplementedError

    def __call__(self, x):
        &#34;&#34;&#34;
        Compute the probability density function in the specified point

        Args:
            x (np.ndarray): the point where the pdf is calculated

        Returns:
            The value of the pdf in the specified point.

        &#34;&#34;&#34;
        raise np.exp(self.log_pdf(x))</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.Distribution" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.Distribution">Distribution</a></li>
<li><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution">TorchDistribution</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution.log_pdf"><code class="name flex">
<span>def <span class="ident">log_pdf</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the logarithm of the probability density function in the
specified point</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>the point where the log pdf is calculated</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The value of the log pdf in the specified point.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def log_pdf(self, x):
    &#34;&#34;&#34;
    Compute the logarithm of the probability density function in the
    specified point

    Args:
        x (np.ndarray): the point where the log pdf is calculated

    Returns:
        The value of the log pdf in the specified point.

    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution.sample"><code class="name flex">
<span>def <span class="ident">sample</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Draw a sample from the distribution.</p>
<h2 id="returns">Returns</h2>
<p>A random vector sampled from the distribution.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sample(self):
    &#34;&#34;&#34;
    Draw a sample from the distribution.

    Returns:
        A random vector sampled from the distribution.

    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.Distribution"><code class="flex name class">
<span>class <span class="ident">Distribution</span></span>
</code></dt>
<dd>
<div class="desc"><p>Interface for Distributions to represent a generic probability distribution.
Probability distributions are often used by black box optimization
algorithms in order to perform exploration in parameter space. In
literature, they are also known as high level policies.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Distribution(AbstractDistribution):
    &#34;&#34;&#34;
    Interface for Distributions to represent a generic probability distribution.
    Probability distributions are often used by black box optimization
    algorithms in order to perform exploration in parameter space. In
    literature, they are also known as high level policies.

    &#34;&#34;&#34;

    def mle(self, theta, weights=None):
        &#34;&#34;&#34;
        Compute the (weighted) maximum likelihood estimate of the points,
        and update the distribution accordingly.

        Args:
            theta (np.ndarray): a set of points, every row is a sample
            weights (np.ndarray, None): a vector of weights. If specified
                                        the weighted maximum likelihood
                                        estimate is computed instead of the
                                        plain maximum likelihood. The number of
                                        elements of this vector must be equal
                                        to the number of rows of the theta
                                        matrix.

        &#34;&#34;&#34;
        raise NotImplementedError

    def diff_log(self, theta):
        &#34;&#34;&#34;
        Compute the derivative of the gradient of the probability denstity
        function in the specified point.

        Args:
            theta (np.ndarray): the point where the gradient of the log pdf is calculated

        Returns:
            The gradient of the log pdf in the specified point.

        &#34;&#34;&#34;
        raise NotImplementedError

    def diff(self, theta):
        &#34;&#34;&#34;
        Compute the derivative of the probability density function, in the
        specified point. Normally it is computed w.r.t. the
        derivative of the logarithm of the probability density function,
        exploiting the likelihood ratio trick, i.e.:

        .. math::
            \\nabla_{\\rho}p(\\theta)=p(\\theta)\\nabla_{\\rho}\\log p(\\theta)

        Args:
            theta (np.ndarray): the point where the gradient of the pdf is
            calculated.

        Returns:
            The gradient of the pdf in the specified point.

        &#34;&#34;&#34;
        return self(theta) * self.diff_log(theta)

    def get_parameters(self):
        &#34;&#34;&#34;
        Getter.

        Returns:
             The current distribution parameters.

        &#34;&#34;&#34;
        raise NotImplementedError

    def set_parameters(self, rho):
        &#34;&#34;&#34;
        Setter.

        Args:
            rho (np.ndarray): the vector of the new parameters to be used by
                              the distribution

        &#34;&#34;&#34;
        raise NotImplementedError

    @property
    def parameters_size(self):
        &#34;&#34;&#34;
        Property.

        Returns:
             The size of the distribution parameters.

        &#34;&#34;&#34;
        raise NotImplementedError</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution">AbstractDistribution</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.Distribution.parameters_size"><code class="name">var <span class="ident">parameters_size</span></code></dt>
<dd>
<div class="desc"><p>Property.</p>
<h2 id="returns">Returns</h2>
<p>The size of the distribution parameters.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def parameters_size(self):
    &#34;&#34;&#34;
    Property.

    Returns:
         The size of the distribution parameters.

    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.Distribution.diff"><code class="name flex">
<span>def <span class="ident">diff</span></span>(<span>self, theta)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the derivative of the probability density function, in the
specified point. Normally it is computed w.r.t. the
derivative of the logarithm of the probability density function,
exploiting the likelihood ratio trick, i.e.:</p>
<p>[ \nabla_{\rho}p(\theta)=p(\theta)\nabla_{\rho}\log p(\theta) ]</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>theta</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>the point where the gradient of the pdf is</dd>
</dl>
<p>calculated.</p>
<h2 id="returns">Returns</h2>
<p>The gradient of the pdf in the specified point.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def diff(self, theta):
    &#34;&#34;&#34;
    Compute the derivative of the probability density function, in the
    specified point. Normally it is computed w.r.t. the
    derivative of the logarithm of the probability density function,
    exploiting the likelihood ratio trick, i.e.:

    .. math::
        \\nabla_{\\rho}p(\\theta)=p(\\theta)\\nabla_{\\rho}\\log p(\\theta)

    Args:
        theta (np.ndarray): the point where the gradient of the pdf is
        calculated.

    Returns:
        The gradient of the pdf in the specified point.

    &#34;&#34;&#34;
    return self(theta) * self.diff_log(theta)</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.Distribution.diff_log"><code class="name flex">
<span>def <span class="ident">diff_log</span></span>(<span>self, theta)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the derivative of the gradient of the probability denstity
function in the specified point.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>theta</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>the point where the gradient of the log pdf is calculated</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The gradient of the log pdf in the specified point.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def diff_log(self, theta):
    &#34;&#34;&#34;
    Compute the derivative of the gradient of the probability denstity
    function in the specified point.

    Args:
        theta (np.ndarray): the point where the gradient of the log pdf is calculated

    Returns:
        The gradient of the log pdf in the specified point.

    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.Distribution.get_parameters"><code class="name flex">
<span>def <span class="ident">get_parameters</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Getter.</p>
<h2 id="returns">Returns</h2>
<p>The current distribution parameters.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_parameters(self):
    &#34;&#34;&#34;
    Getter.

    Returns:
         The current distribution parameters.

    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.Distribution.mle"><code class="name flex">
<span>def <span class="ident">mle</span></span>(<span>self, theta, weights=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the (weighted) maximum likelihood estimate of the points,
and update the distribution accordingly.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>theta</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>a set of points, every row is a sample</dd>
<dt><strong><code>weights</code></strong> :&ensp;<code>np.ndarray, None</code></dt>
<dd>a vector of weights. If specified
the weighted maximum likelihood
estimate is computed instead of the
plain maximum likelihood. The number of
elements of this vector must be equal
to the number of rows of the theta
matrix.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mle(self, theta, weights=None):
    &#34;&#34;&#34;
    Compute the (weighted) maximum likelihood estimate of the points,
    and update the distribution accordingly.

    Args:
        theta (np.ndarray): a set of points, every row is a sample
        weights (np.ndarray, None): a vector of weights. If specified
                                    the weighted maximum likelihood
                                    estimate is computed instead of the
                                    plain maximum likelihood. The number of
                                    elements of this vector must be equal
                                    to the number of rows of the theta
                                    matrix.

    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.Distribution.set_parameters"><code class="name flex">
<span>def <span class="ident">set_parameters</span></span>(<span>self, rho)</span>
</code></dt>
<dd>
<div class="desc"><p>Setter.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>rho</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>the vector of the new parameters to be used by
the distribution</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_parameters(self, rho):
    &#34;&#34;&#34;
    Setter.

    Args:
        rho (np.ndarray): the vector of the new parameters to be used by
                          the distribution

    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution">AbstractDistribution</a></b></code>:
<ul class="hlist">
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution.log_pdf" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution.log_pdf">log_pdf</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution.sample" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution.sample">sample</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.GaussianTorchDistribution"><code class="flex name class">
<span>class <span class="ident">GaussianTorchDistribution</span></span>
<span>(</span><span>mu, chol_flat, use_cuda)</span>
</code></dt>
<dd>
<div class="desc"><p>Interface for a generic PyTorch distribution.
A PyTorch distribution is a distribution implemented using PyTorch.
Functions ending with '_t' use tensors as input, and also as output when
required.</p>
<p>Constructor.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>use_cuda</code></strong> :&ensp;<code>bool</code></dt>
<dd>whether to use cuda or not.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class GaussianTorchDistribution(TorchDistribution):

    def __init__(self, mu, chol_flat, use_cuda):
        super().__init__(use_cuda)
        self._dim = mu.shape[0]

        self._mu = nn.Parameter(torch.as_tensor(mu, dtype=torch.float32), requires_grad=True)
        self._chol_flat = nn.Parameter(torch.as_tensor(chol_flat, dtype=torch.float32), requires_grad=True)

        self.distribution_t = MultivariateNormal(self._mu, scale_tril=self.to_tril_matrix(self._chol_flat, self._dim))

    def __copy__(self):
        return GaussianTorchDistribution(self._mu, self._chol_flat, self.use_cuda)

    def __deepcopy__(self, memodict=None):
        return GaussianTorchDistribution(copy.deepcopy(self._mu), copy.deepcopy(self._chol_flat), self.use_cuda)

    @staticmethod
    def to_tril_matrix(chol_flat, dim):
        if isinstance(chol_flat, np.ndarray):
            chol = np.zeros((dim, dim))
            exp_fun = np.exp
        else:
            chol = torch.zeros((dim, dim))
            exp_fun = torch.exp

        d1, d2 = np.diag_indices(dim)
        chol[d1, d2] += exp_fun(chol_flat[0: dim])
        ld1, ld2 = np.tril_indices(dim, k=-1)
        chol[ld1, ld2] += chol_flat[dim:]

        return chol

    @staticmethod
    def flatten_matrix(mat, tril=False):
        if not tril:
            mat = scpla.cholesky(mat, lower=True)

        dim = mat.shape[0]
        d1, d2 = np.diag_indices(dim)
        ld1, ld2 = np.tril_indices(dim, k=-1)

        return np.concatenate((np.log(mat[d1, d2]), mat[ld1, ld2]))

    def entropy_t(self):
        return self.distribution_t.entropy()

    def mean_t(self):
        return self.distribution_t.mean

    def log_pdf_t(self, x):
        return self.distribution_t.log_prob(x)

    def sample(self):
        return self.distribution_t.rsample()

    def covariance_matrix(self):
        return self.distribution_t.covariance_matrix.detach().numpy()

    def set_weights(self, weights):
        set_weights([self._mu], weights[0:self._dim], self._use_cuda)
        set_weights([self._chol_flat], weights[self._dim:], self._use_cuda)
        # This is important - otherwise the changes will not be reflected!
        self.distribution_t = MultivariateNormal(self._mu, scale_tril=self.to_tril_matrix(self._chol_flat, self._dim))

    def get_weights(self):
        mu_weights = get_weights([self._mu])
        chol_flat_weights = get_weights([self._chol_flat])

        return np.concatenate([mu_weights, chol_flat_weights])

    def parameters(self):
        return [self._mu, self._chol_flat]</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution">TorchDistribution</a></li>
<li><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution">AbstractDistribution</a></li>
<li>abc.ABC</li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.GaussianTorchDistribution.flatten_matrix"><code class="name flex">
<span>def <span class="ident">flatten_matrix</span></span>(<span>mat, tril=False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def flatten_matrix(mat, tril=False):
    if not tril:
        mat = scpla.cholesky(mat, lower=True)

    dim = mat.shape[0]
    d1, d2 = np.diag_indices(dim)
    ld1, ld2 = np.tril_indices(dim, k=-1)

    return np.concatenate((np.log(mat[d1, d2]), mat[ld1, ld2]))</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.GaussianTorchDistribution.to_tril_matrix"><code class="name flex">
<span>def <span class="ident">to_tril_matrix</span></span>(<span>chol_flat, dim)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def to_tril_matrix(chol_flat, dim):
    if isinstance(chol_flat, np.ndarray):
        chol = np.zeros((dim, dim))
        exp_fun = np.exp
    else:
        chol = torch.zeros((dim, dim))
        exp_fun = torch.exp

    d1, d2 = np.diag_indices(dim)
    chol[d1, d2] += exp_fun(chol_flat[0: dim])
    ld1, ld2 = np.tril_indices(dim, k=-1)
    chol[ld1, ld2] += chol_flat[dim:]

    return chol</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.GaussianTorchDistribution.covariance_matrix"><code class="name flex">
<span>def <span class="ident">covariance_matrix</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def covariance_matrix(self):
    return self.distribution_t.covariance_matrix.detach().numpy()</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution">TorchDistribution</a></b></code>:
<ul class="hlist">
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.entropy" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.entropy">entropy</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.entropy_t" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.entropy_t">entropy_t</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.get_weights" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.get_weights">get_weights</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.log_pdf" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution.log_pdf">log_pdf</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.log_pdf_t" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.log_pdf_t">log_pdf_t</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.mean" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.mean">mean</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.mean_t" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.mean_t">mean_t</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.parameters" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.parameters">parameters</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.sample" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution.sample">sample</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.set_weights" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.set_weights">set_weights</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.use_cuda" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.use_cuda">use_cuda</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution"><code class="flex name class">
<span>class <span class="ident">TorchDistribution</span></span>
<span>(</span><span>use_cuda)</span>
</code></dt>
<dd>
<div class="desc"><p>Interface for a generic PyTorch distribution.
A PyTorch distribution is a distribution implemented using PyTorch.
Functions ending with '_t' use tensors as input, and also as output when
required.</p>
<p>Constructor.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>use_cuda</code></strong> :&ensp;<code>bool</code></dt>
<dd>whether to use cuda or not.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TorchDistribution(AbstractDistribution, ABC):
    &#34;&#34;&#34;
    Interface for a generic PyTorch distribution.
    A PyTorch distribution is a distribution implemented using PyTorch.
    Functions ending with &#39;_t&#39; use tensors as input, and also as output when
    required.

    &#34;&#34;&#34;

    def __init__(self, use_cuda):
        &#34;&#34;&#34;
        Constructor.

        Args:
            use_cuda (bool): whether to use cuda or not.

        &#34;&#34;&#34;
        self._use_cuda = use_cuda

    def entropy(self):
        &#34;&#34;&#34;
        Compute the entropy of the policy.

        Returns:
            The value of the entropy of the policy.

        &#34;&#34;&#34;

        return self.entropy_t().detach().cpu().numpy()

    def entropy_t(self):
        &#34;&#34;&#34;
        Compute the entropy of the policy.

        Returns:
            The tensor value of the entropy of the policy.

        &#34;&#34;&#34;
        raise NotImplementedError

    def mean(self):
        &#34;&#34;&#34;
        Compute the mean of the policy.

        Returns:
            The value of the mean of the policy.

        &#34;&#34;&#34;
        return self.mean_t().detach().cpu().numpy()

    def mean_t(self):
        &#34;&#34;&#34;
        Compute the mean of the policy.

        Returns:
            The tensor value of the mean of the policy.

        &#34;&#34;&#34;
        raise NotImplementedError

    def log_pdf(self, x):
        x = to_float_tensor(x, self._use_cuda)
        return self.log_pdf_t(x).detach().cpu().numpy()

    def log_pdf_t(self, x):
        &#34;&#34;&#34;
        Compute the logarithm of the probability density function in the
        specified point

        Args:
            x (torch.Tensor): the point where the log pdf is calculated

        Returns:
            The value of the log pdf in the specified point.

        &#34;&#34;&#34;
        raise NotImplementedError

    def set_weights(self, weights):
        &#34;&#34;&#34;
        Setter.

        Args:
            weights (np.ndarray): the vector of the new weights to be used by the distribution

        &#34;&#34;&#34;
        raise NotImplementedError

    def get_weights(self):
        &#34;&#34;&#34;
        Getter.

        Returns:
             The current policy weights.

        &#34;&#34;&#34;
        raise NotImplementedError

    def parameters(self):
        &#34;&#34;&#34;
        Returns the trainable distribution parameters, as expected by torch optimizers.

        Returns:
            List of parameters to be optimized.

        &#34;&#34;&#34;
        raise NotImplementedError

    def reset(self):
        pass

    @property
    def use_cuda(self):
        &#34;&#34;&#34;
        True if the policy is using cuda_tensors.
        &#34;&#34;&#34;
        return self._use_cuda</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution">AbstractDistribution</a></li>
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.GaussianTorchDistribution" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.GaussianTorchDistribution">GaussianTorchDistribution</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.use_cuda"><code class="name">var <span class="ident">use_cuda</span></code></dt>
<dd>
<div class="desc"><p>True if the policy is using cuda_tensors.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def use_cuda(self):
    &#34;&#34;&#34;
    True if the policy is using cuda_tensors.
    &#34;&#34;&#34;
    return self._use_cuda</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.entropy"><code class="name flex">
<span>def <span class="ident">entropy</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the entropy of the policy.</p>
<h2 id="returns">Returns</h2>
<p>The value of the entropy of the policy.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def entropy(self):
    &#34;&#34;&#34;
    Compute the entropy of the policy.

    Returns:
        The value of the entropy of the policy.

    &#34;&#34;&#34;

    return self.entropy_t().detach().cpu().numpy()</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.entropy_t"><code class="name flex">
<span>def <span class="ident">entropy_t</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the entropy of the policy.</p>
<h2 id="returns">Returns</h2>
<p>The tensor value of the entropy of the policy.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def entropy_t(self):
    &#34;&#34;&#34;
    Compute the entropy of the policy.

    Returns:
        The tensor value of the entropy of the policy.

    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.get_weights"><code class="name flex">
<span>def <span class="ident">get_weights</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Getter.</p>
<h2 id="returns">Returns</h2>
<p>The current policy weights.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_weights(self):
    &#34;&#34;&#34;
    Getter.

    Returns:
         The current policy weights.

    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.log_pdf_t"><code class="name flex">
<span>def <span class="ident">log_pdf_t</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the logarithm of the probability density function in the
specified point</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>torch.Tensor</code></dt>
<dd>the point where the log pdf is calculated</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The value of the log pdf in the specified point.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def log_pdf_t(self, x):
    &#34;&#34;&#34;
    Compute the logarithm of the probability density function in the
    specified point

    Args:
        x (torch.Tensor): the point where the log pdf is calculated

    Returns:
        The value of the log pdf in the specified point.

    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.mean"><code class="name flex">
<span>def <span class="ident">mean</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the mean of the policy.</p>
<h2 id="returns">Returns</h2>
<p>The value of the mean of the policy.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mean(self):
    &#34;&#34;&#34;
    Compute the mean of the policy.

    Returns:
        The value of the mean of the policy.

    &#34;&#34;&#34;
    return self.mean_t().detach().cpu().numpy()</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.mean_t"><code class="name flex">
<span>def <span class="ident">mean_t</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the mean of the policy.</p>
<h2 id="returns">Returns</h2>
<p>The tensor value of the mean of the policy.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mean_t(self):
    &#34;&#34;&#34;
    Compute the mean of the policy.

    Returns:
        The tensor value of the mean of the policy.

    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.parameters"><code class="name flex">
<span>def <span class="ident">parameters</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the trainable distribution parameters, as expected by torch optimizers.</p>
<h2 id="returns">Returns</h2>
<p>List of parameters to be optimized.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parameters(self):
    &#34;&#34;&#34;
    Returns the trainable distribution parameters, as expected by torch optimizers.

    Returns:
        List of parameters to be optimized.

    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.reset"><code class="name flex">
<span>def <span class="ident">reset</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset(self):
    pass</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.set_weights"><code class="name flex">
<span>def <span class="ident">set_weights</span></span>(<span>self, weights)</span>
</code></dt>
<dd>
<div class="desc"><p>Setter.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>weights</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>the vector of the new weights to be used by the distribution</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_weights(self, weights):
    &#34;&#34;&#34;
    Setter.

    Args:
        weights (np.ndarray): the vector of the new weights to be used by the distribution

    &#34;&#34;&#34;
    raise NotImplementedError</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution">AbstractDistribution</a></b></code>:
<ul class="hlist">
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution.log_pdf" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution.log_pdf">log_pdf</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution.sample" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution.sample">sample</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<a href="http://developmentalsystems.org/TeachMyAgent/doc/">
<img src="https://github.com/flowersteam/TeachMyAgent/blob/gh-pages/images/home/head_image.png?raw=true" style="display: block; margin: 1em auto">
</a>
<a href="http://developmentalsystems.org/TeachMyAgent/doc/">Home</a> | <a href="http://developmentalsystems.org/TeachMyAgent/">Website</a>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="TeachMyAgent.teachers.utils" href="index.html">TeachMyAgent.teachers.utils</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution">AbstractDistribution</a></code></h4>
<ul class="">
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution.log_pdf" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution.log_pdf">log_pdf</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution.sample" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.AbstractDistribution.sample">sample</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.Distribution" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.Distribution">Distribution</a></code></h4>
<ul class="two-column">
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.Distribution.diff" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.Distribution.diff">diff</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.Distribution.diff_log" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.Distribution.diff_log">diff_log</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.Distribution.get_parameters" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.Distribution.get_parameters">get_parameters</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.Distribution.mle" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.Distribution.mle">mle</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.Distribution.parameters_size" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.Distribution.parameters_size">parameters_size</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.Distribution.set_parameters" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.Distribution.set_parameters">set_parameters</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.GaussianTorchDistribution" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.GaussianTorchDistribution">GaussianTorchDistribution</a></code></h4>
<ul class="">
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.GaussianTorchDistribution.covariance_matrix" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.GaussianTorchDistribution.covariance_matrix">covariance_matrix</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.GaussianTorchDistribution.flatten_matrix" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.GaussianTorchDistribution.flatten_matrix">flatten_matrix</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.GaussianTorchDistribution.to_tril_matrix" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.GaussianTorchDistribution.to_tril_matrix">to_tril_matrix</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution">TorchDistribution</a></code></h4>
<ul class="two-column">
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.entropy" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.entropy">entropy</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.entropy_t" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.entropy_t">entropy_t</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.get_weights" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.get_weights">get_weights</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.log_pdf_t" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.log_pdf_t">log_pdf_t</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.mean" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.mean">mean</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.mean_t" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.mean_t">mean_t</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.parameters" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.parameters">parameters</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.reset" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.reset">reset</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.set_weights" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.set_weights">set_weights</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.use_cuda" href="#TeachMyAgent.teachers.utils.gaussian_torch_distribution.TorchDistribution.use_cuda">use_cuda</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>