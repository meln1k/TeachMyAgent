<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>TeachMyAgent.teachers.utils.setter_solver_utils API documentation</title>
<meta name="description" content="Copyright 2020 Google LLC …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<link rel="icon" href="https://github.com/flowersteam/TeachMyAgent/blob/gh-pages/images/favicon-96x96.png?raw=true" />
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>TeachMyAgent.teachers.utils.setter_solver_utils</code></h1>
</header>
<section id="section-intro">
<p>Copyright 2020 Google LLC</p>
<p>Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at</p>
<pre><code>&lt;https://www.apache.org/licenses/LICENSE-2.0&gt;
</code></pre>
<p>Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.</p>
<p>This file contains tensorflow building blocks for
<code>Automated curricula through setter-solver interactions</code>, S. Racaniere &amp; A. K. Lampinen, ICLR 2020.</p>
<p>This code is provided to help with reproducibility of the results of the paper.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Copyright 2020 Google LLC

Licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    https://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.


This file contains tensorflow building blocks for
`Automated curricula through setter-solver interactions`, S. Racaniere &amp; A. K. Lampinen, ICLR 2020.

This code is provided to help with reproducibility of the results of the paper.
&#34;&#34;&#34;
# Modified by Clément Romac, copy of the license at TeachMyAgent/teachers/LICENSES/Setter-Solver

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import functools
import numpy as np
import sonnet as snt
import tensorflow as tf


_MIN_SCALE = 1e-2


def _highway_block(inputs, hidden_size=32):
  &#34;&#34;&#34;A simple highway block with a single gate.

  The block was previously used in Zilly et al, &#34;Recurrent Highway Networks&#34;:
  https://arxiv.org/abs/1607.03474

  Args:
    inputs: An input `Tensor` with shape `[batch_size, hidden_size]`.
    hidden_size: The size on the residual connections.

  Returns:
    A `Tensor` with the same shape as the input.
  &#34;&#34;&#34;
  inputs.get_shape().assert_has_rank(2)

  to_gates = snt.Linear(2 * hidden_size)(inputs)
  to_tanh, to_gate = tf.split(to_gates, 2, axis=-1)
  gate = tf.sigmoid(to_gate)
  return inputs + (tf.tanh(to_tanh) - inputs) * gate


class Highway(snt.AbstractModule):
  &#34;&#34;&#34;A linear network with multiple highway blocks.

  This architecture was introduced in Zilly et al, &#34;Recurrent Highway Networks&#34;:
  https://arxiv.org/abs/1607.03474
  &#34;&#34;&#34;

  def __init__(self,
               output_size,
               num_blocks=4,
               hidden_size=32,
               zero_init_last_layer=False,
               name=&#39;highway&#39;):
    &#34;&#34;&#34;Constructs the network.

    Args:
      output_size: The wanted number of outputs.
      num_blocks: The number of highway blocks.
      hidden_size: The size on the residual connections.
      zero_init_last_layer: Whether to initialize the last convolution with 0&#39;s.
        This makes the transform an identity op in a RVNP-like architecture.
        See GLOW (https://arxiv.org/abs/1807.03039) for more details.
      name: Name of the module.
    &#34;&#34;&#34;
    super(Highway, self).__init__(name=name)
    self._output_size = output_size
    self._num_blocks = num_blocks
    self._hidden_size = hidden_size
    self._zero_init_last_layer = zero_init_last_layer

  def _build(self, inputs):
    &#34;&#34;&#34;Runs the network on the given input.

    Args:
      inputs: A `Tensor` with shape `[batch_size, hidden_size]`.

    Returns:
      A `Tensor` with shape `[batch_size, output_size]`.
    &#34;&#34;&#34;

    def _block(y):
      return _highway_block(y, hidden_size=self._hidden_size)

    y = snt.Linear(self._hidden_size)(inputs)
    # Starting with tanh.
    y = tf.tanh(y)
    for _ in range(self._num_blocks):
      y = _block(y)

    if self._zero_init_last_layer:
      final_layer_initializers = {&#39;w&#39;: tf.zeros_initializer()}
    else:
      final_layer_initializers = None

    y = snt.Linear(self._output_size, initializers=final_layer_initializers)(y)
    return y


def non_zero_uniform(shape):
  &#34;&#34;&#34;Samples in open range (0, 1).

  This avoids the value 0, which can be returned by tf.random.uniform, by
  replacing all 0 values with 0.5.

  Args:
    shape: a list or tuple of integers.

  Returns:
    A Tensor of the given shape, a dtype of float32, and all values in the open
    interval (0, 1).
  &#34;&#34;&#34;
  rnd = tf.random.uniform(shape, dtype=tf.float32)
  return tf.where(tf.equal(rnd, 0.), tf.ones_like(rnd) / 2., rnd)


def _add_condition(z, condition):
  if condition is not None:
    return tf.concat([z, condition], axis=1)
  else:
    return z


def _inverse_sigmoid(x):
  &#34;&#34;&#34;Inverts a sigmoid.&#34;&#34;&#34;
  return -tf.math.log(1. / x - 1)


def _log_sigmoid(x):
  &#34;&#34;&#34;Computes log(sigmoid(x)) while avoiding 0 or infinity on the output.&#34;&#34;&#34;
  # If \sigma is the sigmoid function, then
  # log \sigma(x) = -log(1 + e^{-x}) = -softplus(-a)
  return -tf.math.softplus(-x)


class ClippedSigmoid(object):
  &#34;&#34;&#34;Sigmoid function with clipped values to avoid overflows.&#34;&#34;&#34;

  def __init__(self, clip=None):
    if clip is None:
      self._x_clip = None
      self._y_clip = None
    else:
      self._x_clip = clip
      self._y_clip = np.tanh(clip / 2) / 2 + 0.5

  def _clip(self, x):
    if self._x_clip is None:
      return x
    else:
      return tf.clip_by_value(x, -self._x_clip, self._x_clip)

  def _clip_inverse(self, y):
    if self._y_clip is None:
      return y
    else:
      return tf.clip_by_value(y, -self._y_clip, self._y_clip)

  def apply(self, x):
    x = self._clip(x)
    return tf.sigmoid(x)

  def inverse(self, y):
    y = self._clip_inverse(y)
    return _inverse_sigmoid(y)

  def log_differential(self, x):
    x = self._clip(x)
    # Recall \sigma&#39;(x) = \sigma(x) \times \sigma(-x).
    return _log_sigmoid(x) + _log_sigmoid(-x)

class NothingActivationFunction():
  def apply(self, x):
    return x

  def inverse(self, y):
    return y

  def log_differential(self, x):
    return x


def _soft_clip(x, max_abs):
  &#34;&#34;&#34;Clips values in range (-max_abs, max_abs) in a soft manner.&#34;&#34;&#34;
  scale = max_abs / (np.pi / 2.)
  return scale * tf.math.atan(x / scale)


def _softplus(x):
  &#34;&#34;&#34;A nice softplus.

  This is a monotonous function that is equivalent to x at +inf and
  -1 / (3PI x^2) at -inf. To prove this, use two facts:
  1. For negative x, atan(x) = -PI/2 - artan(1/x)
  2. Near 0, atan(x) = x - x^3/3 + O(x^5)
  From these two things, you can deduce that as x -&gt; -inf:
    atan(x) = -PI/2 - 1/x + 1 / 3x^3 + O(1/x^5).
  This is enough to prove the statement.

  This function decays much slower than the softplus
  from tf.math.softplus at -inf, which decays as exp(x).

  Args:
    x: a Tensor.

  Returns:
    A Tensor of the same type and shape as x.
  &#34;&#34;&#34;
  x = _soft_clip(x, 1e6)
  y = x * (tf.math.atan(x) / np.pi + 0.5) + 1 / np.pi
  # Mathematically, y above is equivalent to -1/ (3PI x^2) as x goes to -inf,
  # but because of numerical instabilities, the value of y sometimes end up
  # negative.
  # For example, at the time of writing, y is equal to -0.00113806 when
  # x = -33920.55078125. We fix this with the tf.where below.
  equiv_y = 1 / (3 * np.pi * tf.square(x))
  return tf.where(x &lt; -30., equiv_y, y)


def _interlace(z1, z2):
  &#34;&#34;&#34;Interlace batched flat Tensors.

  See test for an example.

  This is basically the reverse operation of extracting odd and even position
  values. This method satisfies that for any Tensor z:
  z = _interlace(z[:, ::2], z[:, 1::2]).

  Args:
    z1: a Tensor of shape [B, N]
    z2: a Tensor of shape [B, N] or [B, N - 1]

  Returns:
    A Tensor.

  Raises:
    ValueError: if the shapes of z1 and z2 are wrong.
  &#34;&#34;&#34;
  n1 = z1.get_shape()[1].value
  n2 = z2.get_shape()[1].value
  if n2 not in (n1, n1 - 1):
    raise ValueError(
        &#39;z2 ({}) should be the same shape or 1 shorter than z1 ({}).&#39;.format(
            z2.get_shape().as_list(),
            z1.get_shape().as_list()))
  if n2 &lt; n1:
    # Add some padding.
    z2 = tf.concat([z2, tf.zeros_like(z2[:, :1])], axis=-1)
  z = tf.stack([z1, z2], axis=1)
  z = tf.transpose(z, perm=[0, 2, 1])
  z = tf.reshape(z, shape=[-1, n1 * 2])
  if n2 &lt; n1:
    # Remove the padding.
    z = z[:, :-1]
  return z

class FlatRnvp(snt.AbstractModule):
  &#34;&#34;&#34;An R-NVP for flat Tensors.

  The main methods are `sample` and `infer`. The `sample(batch_size)` method
  returns a batch of Tensors and their respective log probabilities. The
  `infer(samples)` method returns the inferred samples from the base
  distribution as well as the log probabilities of the input samples.
  &#34;&#34;&#34;

  def __init__(self,
               latent_size,
               num_blocks,
               num_layers_per_block,
               tf_session,
               judge_output_op,
               hidden_size=None,
               custom_getter=None,
               activation=tf.nn.leaky_relu,
               final_non_linearity=ClippedSigmoid,
               loss_noise_ub=0.0,
               random_state=np.random.RandomState(seed=24),
               name=&#39;flat_rnvp&#39;):
    super(FlatRnvp, self).__init__(custom_getter=custom_getter, name=name)
    self.tf_session = tf_session
    self._latent_size = latent_size
    self._num_blocks = num_blocks
    self._num_layers_per_block = num_layers_per_block
    self._hidden_size = hidden_size
    self._activation = activation
    # Note that latent_size might not be even
    self._n1 = latent_size // 2
    # Layers created during `sample` are reused during `infer`.
    self._layers = None
    self._logit_goals = final_non_linearity == ClippedSigmoid
    self._final_non_linearity = final_non_linearity()
    self._loss_noise_ub = loss_noise_ub
    self._random_state = random_state

    self()
    self._judge_output_op = judge_output_op
    self._loss = self._set_loss()
    self._optimizer = tf.train.AdamOptimizer(learning_rate=3e-4).minimize(self._loss, var_list=self._local_variables)

  def _split(self, z):
    z1 = z[:, :self._n1]
    z2 = z[:, self._n1:]
    return z1, z2

  def _build_sample(self, latent, condition):
    self._layers = []
    log_p = -0.5 * tf.reduce_sum(tf.square(latent), axis=1)
    for _ in range(self._num_blocks):
      latent, log_p = self._block_transform(latent, log_p, condition)
    logit = tf.debugging.check_numerics(latent, &#39;goal latent&#39;)
    log_p = log_p - tf.reduce_sum(
      self._final_non_linearity.log_differential(logit), axis=1)
    return self._final_non_linearity.apply(logit), log_p

  def _build_infer(self, samples, condition):
    z = self._final_non_linearity.inverse(samples)
    log_p = -tf.reduce_sum(self._final_non_linearity.log_differential(z),
                           axis=1)
    log_p = tf.debugging.check_numerics(log_p, &#39;initial_log_p&#39;)
    for block_layers in self._layers[::-1]:
      z, log_p = self._inverse_block_transform(
        z, log_p, condition, block_layers)
    log_p = tf.debugging.check_numerics(log_p, &#39;reverse_log_p&#39;)
    log_p -= 0.5 * tf.reduce_sum(tf.square(z), axis=1)
    log_p = tf.debugging.check_numerics(log_p, &#39;final_log_p&#39;)
    return z, log_p

  def _build(self):
    # We rebuild the layers at each call. This does not matter because of the
    # automatic variables sharing, and it simplifies the code to always rebuild.
    self._latent = tf.placeholder(tf.float64, shape=(None, self._latent_size))
    self._samples = tf.placeholder(tf.float64, shape=(None, self._latent_size))
    self._sample_condition = tf.placeholder(tf.float64, shape=(None, 1))
    self._infer_condition = tf.placeholder(tf.float64, shape=(None, 1))

    self.sample_output, self.sample_log_p = self._build_sample(self._latent, self._sample_condition)
    self.infer_output, self.infer_log_p = self._build_infer(self._samples, self._infer_condition)
    self._local_variables = tf.get_collection( # used to avoid training judge&#39;s variables
      tf.GraphKeys.TRAINABLE_VARIABLES,
      self._original_name
    )

  def _set_loss(self):
    feasibility_loss = tf.math.reduce_mean(
      tf.math.squared_difference(self._judge_output_op(self.sample_output),
                                 _inverse_sigmoid(self._sample_condition)))
    validity_loss = tf.math.reduce_mean(-self.infer_log_p)
    cover_loss = tf.math.reduce_mean(self.sample_log_p)

    return feasibility_loss + validity_loss + cover_loss

  def sample(self, batch_size, condition=None):
    latent = self._random_state.normal(size=[batch_size, self._latent_size]) # mean: 0, std: 1
    return self.tf_session.run([self.sample_output, self.sample_log_p],
                               feed_dict={self._latent: latent, self._sample_condition: condition})

  def infer(self, samples, condition=None):
    if self._layers is None:
      raise RuntimeError(
          &#39;You need to have called `sample()` at least once before calling &#39;
          &#39;`infer()`&#39;)

    return self.tf_session.run([self.infer_output, self.infer_log_p],
                               feed_dict={self._samples: samples, self._infer_condition: condition})

  def train(self, samples, feasibilities, returns):
    reshaped_returns = returns.reshape((len(returns),))
    succeeded_goals = samples[reshaped_returns == 1]
    succeeded_feasibilities = feasibilities[reshaped_returns == 1]

    noise = self._random_state.uniform(low=0, high=self._loss_noise_ub, size=succeeded_goals.shape)
    noisy_succeeded_goals = succeeded_goals+noise
    if self._logit_goals:
      noisy_succeeded_goals = np.clip(noisy_succeeded_goals, 1e-4, 1 - 1e-4) # clip to match sigmoid

    latent = self.tf_session.run(self.infer_output, feed_dict={self._samples: samples, self._infer_condition:feasibilities})
    return self.tf_session.run([self._loss, self._optimizer],
                               feed_dict={
                                 self._samples: noisy_succeeded_goals,
                                 self._infer_condition: succeeded_feasibilities,
                                 self._sample_condition: feasibilities,
                                 self._latent: latent # np.clip(latent , 1e-4, 1 - 1e-4)
                               })


  def _block_transform(self, z, log_p, condition):
    &#34;&#34;&#34;Builds a block used inside an RNVP.&#34;&#34;&#34;
    self._layers.append([])
    z, log_p = self._left_to_right_transform(z, log_p, condition,
                                             self._transform)
    z, log_p = self._right_to_left_transform(z, log_p, condition,
                                             self._transform)
    z, log_p = self._interlaced_transform(z, log_p, condition, self._transform)
    return z, log_p

  def _inverse_block_transform(self, z, log_p, condition, block_layers):
    left_to_right, right_to_left, interlace = block_layers
    # Go in reverse order from the transforms in `_block_transform`
    s_net, t_net = interlace
    transform = functools.partial(
        self._inverse_transform, s_net=s_net, t_net=t_net)
    z, log_p = self._interlaced_transform(z, log_p, condition, transform)
    s_net, t_net = right_to_left
    transform = functools.partial(
        self._inverse_transform, s_net=s_net, t_net=t_net)
    z, log_p = self._right_to_left_transform(z, log_p, condition, transform)
    s_net, t_net = left_to_right
    transform = functools.partial(
        self._inverse_transform, s_net=s_net, t_net=t_net)
    z, log_p = self._left_to_right_transform(z, log_p, condition, transform)
    return z, log_p

  def _transform(self, z1, z2, log_p, condition):
    # Implement the update from the RNVP paper, using their notation. Below,
    # replace the exp(s) in the original paper with _softplus in
    # order to get more stable learning.
    zz = _add_condition(z1, condition)
    n = z2.get_shape()[1].value
    if self._hidden_size is None:
      hidden_size = n
    else:
      hidden_size = self._hidden_size
    s_net = Highway(
        output_size=n,
        hidden_size=hidden_size,
        num_blocks=self._num_layers_per_block,
        name=&#39;scale&#39;)
    t_net = Highway(
        output_size=n,
        hidden_size=hidden_size,
        num_blocks=self._num_layers_per_block,
        name=&#39;translation&#39;)
    self._layers[-1].append((s_net, t_net))
    s = s_net(zz)
    t = t_net(zz)
    scale = _MIN_SCALE + _softplus(s)
    z2_out = z2 * scale + t
    log_p_out = log_p - tf.reduce_sum(tf.log(scale), axis=-1)

    return z2_out, log_p_out

  def _inverse_transform(self, z1, z2, log_p, condition, s_net, t_net):
    zz = _add_condition(z1, condition)
    s = s_net(zz)
    t = t_net(zz)
    # The division below can lead to very large numbers if we allow the scale
    # to get very small. This effect can compound over multiple layers. That&#39;s
    # why we add _MIN_SCALE below.
    scale = _MIN_SCALE + _softplus(s)
    z2_out = (z2 - t) / scale
    log_p_out = log_p - tf.reduce_sum(tf.log(scale), axis=-1)
    return z2_out, log_p_out

  def _left_to_right_transform(self, z, log_p, condition, transform_fn):
    &#34;&#34;&#34;Affine coupling layer from the RNVP paper.&#34;&#34;&#34;
    z.get_shape().assert_has_rank(2)
    log_p.get_shape().assert_has_rank(1)
    z1, z2 = self._split(z)
    z2_out, log_p_out = transform_fn(z1, z2, log_p, condition)
    return tf.concat([z1, z2_out], axis=-1), log_p_out

  def _right_to_left_transform(self, z, log_p, condition, transform_fn):
    &#34;&#34;&#34;Affine coupling layer from the RNVP paper.&#34;&#34;&#34;
    z.get_shape().assert_has_rank(2)
    log_p.get_shape().assert_has_rank(1)
    z1, z2 = self._split(z)
    # reverse the order of z1 and z2 to get a right to left transform
    z1_out, log_p_out = transform_fn(z2, z1, log_p, condition)
    return tf.concat([z1_out, z2], axis=-1), log_p_out

  def _interlaced_transform(self, z, log_p, condition, transform_fn):
    &#34;&#34;&#34;Affine coupling layer from the RNVP paper.&#34;&#34;&#34;
    z.get_shape().assert_has_rank(2)
    log_p.get_shape().assert_has_rank(1)
    z1 = z[:, ::2]
    z2 = z[:, 1::2]
    z1_out, log_p_out = transform_fn(z2, z1, log_p, condition)
    return _interlace(z1_out, z2), log_p_out


class Judge(snt.AbstractModule):
  &#34;&#34;&#34;Computes logits for probability of a goal being solvable.&#34;&#34;&#34;

  def __init__(self, hidden_sizes, tf_session, goal_size, custom_getter=None, name=&#39;judge&#39;):
    super(Judge, self).__init__(custom_getter=custom_getter, name=name)
    self._layer_sizes = hidden_sizes + [1]
    self.tf_session = tf_session
    self._goal_size = goal_size
    self()
    self._loss = self._set_loss()
    self._optimizer = tf.train.AdamOptimizer(learning_rate=3e-4).minimize(self._loss)

  def _build(self):
    self._mlp = snt.nets.MLP(self._layer_sizes[1:])
    self._goal = tf.placeholder(tf.float64, shape=(None, self._goal_size))
    goal_flat = snt.BatchFlatten()(self._goal)
    self.output = self._mlp(goal_flat) # get non-activated output

  def _set_loss(self):
    self._loss_returns = tf.placeholder(tf.float64, shape=(None, 1))
    return tf.reduce_mean(
      tf.nn.sigmoid_cross_entropy_with_logits(labels=self._loss_returns, logits=self.output))

  def train(self, returns, samples):
    return self.tf_session.run([self._loss, self._optimizer],
                               feed_dict={
                                 self._loss_returns: returns,
                                 self._goal: samples
                               })

  def calculate_feasibility(self, goal):
    return self.tf_session.run(self.output, feed_dict={self._goal: goal})</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="TeachMyAgent.teachers.utils.setter_solver_utils.non_zero_uniform"><code class="name flex">
<span>def <span class="ident">non_zero_uniform</span></span>(<span>shape)</span>
</code></dt>
<dd>
<div class="desc"><p>Samples in open range (0, 1).</p>
<p>This avoids the value 0, which can be returned by tf.random.uniform, by
replacing all 0 values with 0.5.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>shape</code></strong></dt>
<dd>a list or tuple of integers.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A Tensor of the given shape, a dtype of float32, and all values in the open
interval (0, 1).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def non_zero_uniform(shape):
  &#34;&#34;&#34;Samples in open range (0, 1).

  This avoids the value 0, which can be returned by tf.random.uniform, by
  replacing all 0 values with 0.5.

  Args:
    shape: a list or tuple of integers.

  Returns:
    A Tensor of the given shape, a dtype of float32, and all values in the open
    interval (0, 1).
  &#34;&#34;&#34;
  rnd = tf.random.uniform(shape, dtype=tf.float32)
  return tf.where(tf.equal(rnd, 0.), tf.ones_like(rnd) / 2., rnd)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="TeachMyAgent.teachers.utils.setter_solver_utils.ClippedSigmoid"><code class="flex name class">
<span>class <span class="ident">ClippedSigmoid</span></span>
<span>(</span><span>clip=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Sigmoid function with clipped values to avoid overflows.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ClippedSigmoid(object):
  &#34;&#34;&#34;Sigmoid function with clipped values to avoid overflows.&#34;&#34;&#34;

  def __init__(self, clip=None):
    if clip is None:
      self._x_clip = None
      self._y_clip = None
    else:
      self._x_clip = clip
      self._y_clip = np.tanh(clip / 2) / 2 + 0.5

  def _clip(self, x):
    if self._x_clip is None:
      return x
    else:
      return tf.clip_by_value(x, -self._x_clip, self._x_clip)

  def _clip_inverse(self, y):
    if self._y_clip is None:
      return y
    else:
      return tf.clip_by_value(y, -self._y_clip, self._y_clip)

  def apply(self, x):
    x = self._clip(x)
    return tf.sigmoid(x)

  def inverse(self, y):
    y = self._clip_inverse(y)
    return _inverse_sigmoid(y)

  def log_differential(self, x):
    x = self._clip(x)
    # Recall \sigma&#39;(x) = \sigma(x) \times \sigma(-x).
    return _log_sigmoid(x) + _log_sigmoid(-x)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="TeachMyAgent.teachers.utils.setter_solver_utils.ClippedSigmoid.apply"><code class="name flex">
<span>def <span class="ident">apply</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply(self, x):
  x = self._clip(x)
  return tf.sigmoid(x)</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.teachers.utils.setter_solver_utils.ClippedSigmoid.inverse"><code class="name flex">
<span>def <span class="ident">inverse</span></span>(<span>self, y)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def inverse(self, y):
  y = self._clip_inverse(y)
  return _inverse_sigmoid(y)</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.teachers.utils.setter_solver_utils.ClippedSigmoid.log_differential"><code class="name flex">
<span>def <span class="ident">log_differential</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def log_differential(self, x):
  x = self._clip(x)
  # Recall \sigma&#39;(x) = \sigma(x) \times \sigma(-x).
  return _log_sigmoid(x) + _log_sigmoid(-x)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="TeachMyAgent.teachers.utils.setter_solver_utils.FlatRnvp"><code class="flex name class">
<span>class <span class="ident">FlatRnvp</span></span>
<span>(</span><span>latent_size, num_blocks, num_layers_per_block, tf_session, judge_output_op, hidden_size=None, custom_getter=None, activation=&lt;function leaky_relu&gt;, final_non_linearity=TeachMyAgent.teachers.utils.setter_solver_utils.ClippedSigmoid, loss_noise_ub=0.0, random_state=RandomState(MT19937), name='flat_rnvp')</span>
</code></dt>
<dd>
<div class="desc"><p>An R-NVP for flat Tensors.</p>
<p>The main methods are <code>sample</code> and <code>infer</code>. The <code>sample(batch_size)</code> method
returns a batch of Tensors and their respective log probabilities. The
<code>infer(samples)</code> method returns the inferred samples from the base
distribution as well as the log probabilities of the input samples.</p>
<p>Performs the initialisation necessary for all AbstractModule instances.</p>
<p>Every subclass of AbstractModule must begin their constructor with a call to
this constructor, i.e.</p>
<p><code>super(MySubModule, self).__init__(custom_getter=custom_getter, name=name)</code>.</p>
<p>If you instantiate sub-modules in <strong>init</strong> you must create them within the
<code>_enter_variable_scope</code> context manager to ensure they are in the module's
variable scope. Alternatively, instantiate sub-modules in <code>_build</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>_sentinel</code></strong></dt>
<dd>Variable that only carries a non-None value if <code>__init__</code> was
called without named parameters. If this is the case, a deprecation
warning is issued in form of a <code>ValueError</code>.</dd>
<dt><strong><code>custom_getter</code></strong></dt>
<dd>Callable or dictionary of callables to use as
custom getters inside the module. If a dictionary, the keys
correspond to regexes to match variable names. See the <code>tf.get_variable</code>
documentation for information about the custom_getter API.</dd>
<dt><strong><code>name</code></strong></dt>
<dd>Name of this module. Used to construct the Templated build function.
If <code>None</code> the module's class name is used (converted to snake case).</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>TypeError</code></dt>
<dd>If <code>name</code> is not a string.</dd>
<dt><code>TypeError</code></dt>
<dd>If a given <code>custom_getter</code> is not callable.</dd>
<dt><code>ValueError</code></dt>
<dd>If <code>__init__</code> was called without named arguments.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class FlatRnvp(snt.AbstractModule):
  &#34;&#34;&#34;An R-NVP for flat Tensors.

  The main methods are `sample` and `infer`. The `sample(batch_size)` method
  returns a batch of Tensors and their respective log probabilities. The
  `infer(samples)` method returns the inferred samples from the base
  distribution as well as the log probabilities of the input samples.
  &#34;&#34;&#34;

  def __init__(self,
               latent_size,
               num_blocks,
               num_layers_per_block,
               tf_session,
               judge_output_op,
               hidden_size=None,
               custom_getter=None,
               activation=tf.nn.leaky_relu,
               final_non_linearity=ClippedSigmoid,
               loss_noise_ub=0.0,
               random_state=np.random.RandomState(seed=24),
               name=&#39;flat_rnvp&#39;):
    super(FlatRnvp, self).__init__(custom_getter=custom_getter, name=name)
    self.tf_session = tf_session
    self._latent_size = latent_size
    self._num_blocks = num_blocks
    self._num_layers_per_block = num_layers_per_block
    self._hidden_size = hidden_size
    self._activation = activation
    # Note that latent_size might not be even
    self._n1 = latent_size // 2
    # Layers created during `sample` are reused during `infer`.
    self._layers = None
    self._logit_goals = final_non_linearity == ClippedSigmoid
    self._final_non_linearity = final_non_linearity()
    self._loss_noise_ub = loss_noise_ub
    self._random_state = random_state

    self()
    self._judge_output_op = judge_output_op
    self._loss = self._set_loss()
    self._optimizer = tf.train.AdamOptimizer(learning_rate=3e-4).minimize(self._loss, var_list=self._local_variables)

  def _split(self, z):
    z1 = z[:, :self._n1]
    z2 = z[:, self._n1:]
    return z1, z2

  def _build_sample(self, latent, condition):
    self._layers = []
    log_p = -0.5 * tf.reduce_sum(tf.square(latent), axis=1)
    for _ in range(self._num_blocks):
      latent, log_p = self._block_transform(latent, log_p, condition)
    logit = tf.debugging.check_numerics(latent, &#39;goal latent&#39;)
    log_p = log_p - tf.reduce_sum(
      self._final_non_linearity.log_differential(logit), axis=1)
    return self._final_non_linearity.apply(logit), log_p

  def _build_infer(self, samples, condition):
    z = self._final_non_linearity.inverse(samples)
    log_p = -tf.reduce_sum(self._final_non_linearity.log_differential(z),
                           axis=1)
    log_p = tf.debugging.check_numerics(log_p, &#39;initial_log_p&#39;)
    for block_layers in self._layers[::-1]:
      z, log_p = self._inverse_block_transform(
        z, log_p, condition, block_layers)
    log_p = tf.debugging.check_numerics(log_p, &#39;reverse_log_p&#39;)
    log_p -= 0.5 * tf.reduce_sum(tf.square(z), axis=1)
    log_p = tf.debugging.check_numerics(log_p, &#39;final_log_p&#39;)
    return z, log_p

  def _build(self):
    # We rebuild the layers at each call. This does not matter because of the
    # automatic variables sharing, and it simplifies the code to always rebuild.
    self._latent = tf.placeholder(tf.float64, shape=(None, self._latent_size))
    self._samples = tf.placeholder(tf.float64, shape=(None, self._latent_size))
    self._sample_condition = tf.placeholder(tf.float64, shape=(None, 1))
    self._infer_condition = tf.placeholder(tf.float64, shape=(None, 1))

    self.sample_output, self.sample_log_p = self._build_sample(self._latent, self._sample_condition)
    self.infer_output, self.infer_log_p = self._build_infer(self._samples, self._infer_condition)
    self._local_variables = tf.get_collection( # used to avoid training judge&#39;s variables
      tf.GraphKeys.TRAINABLE_VARIABLES,
      self._original_name
    )

  def _set_loss(self):
    feasibility_loss = tf.math.reduce_mean(
      tf.math.squared_difference(self._judge_output_op(self.sample_output),
                                 _inverse_sigmoid(self._sample_condition)))
    validity_loss = tf.math.reduce_mean(-self.infer_log_p)
    cover_loss = tf.math.reduce_mean(self.sample_log_p)

    return feasibility_loss + validity_loss + cover_loss

  def sample(self, batch_size, condition=None):
    latent = self._random_state.normal(size=[batch_size, self._latent_size]) # mean: 0, std: 1
    return self.tf_session.run([self.sample_output, self.sample_log_p],
                               feed_dict={self._latent: latent, self._sample_condition: condition})

  def infer(self, samples, condition=None):
    if self._layers is None:
      raise RuntimeError(
          &#39;You need to have called `sample()` at least once before calling &#39;
          &#39;`infer()`&#39;)

    return self.tf_session.run([self.infer_output, self.infer_log_p],
                               feed_dict={self._samples: samples, self._infer_condition: condition})

  def train(self, samples, feasibilities, returns):
    reshaped_returns = returns.reshape((len(returns),))
    succeeded_goals = samples[reshaped_returns == 1]
    succeeded_feasibilities = feasibilities[reshaped_returns == 1]

    noise = self._random_state.uniform(low=0, high=self._loss_noise_ub, size=succeeded_goals.shape)
    noisy_succeeded_goals = succeeded_goals+noise
    if self._logit_goals:
      noisy_succeeded_goals = np.clip(noisy_succeeded_goals, 1e-4, 1 - 1e-4) # clip to match sigmoid

    latent = self.tf_session.run(self.infer_output, feed_dict={self._samples: samples, self._infer_condition:feasibilities})
    return self.tf_session.run([self._loss, self._optimizer],
                               feed_dict={
                                 self._samples: noisy_succeeded_goals,
                                 self._infer_condition: succeeded_feasibilities,
                                 self._sample_condition: feasibilities,
                                 self._latent: latent # np.clip(latent , 1e-4, 1 - 1e-4)
                               })


  def _block_transform(self, z, log_p, condition):
    &#34;&#34;&#34;Builds a block used inside an RNVP.&#34;&#34;&#34;
    self._layers.append([])
    z, log_p = self._left_to_right_transform(z, log_p, condition,
                                             self._transform)
    z, log_p = self._right_to_left_transform(z, log_p, condition,
                                             self._transform)
    z, log_p = self._interlaced_transform(z, log_p, condition, self._transform)
    return z, log_p

  def _inverse_block_transform(self, z, log_p, condition, block_layers):
    left_to_right, right_to_left, interlace = block_layers
    # Go in reverse order from the transforms in `_block_transform`
    s_net, t_net = interlace
    transform = functools.partial(
        self._inverse_transform, s_net=s_net, t_net=t_net)
    z, log_p = self._interlaced_transform(z, log_p, condition, transform)
    s_net, t_net = right_to_left
    transform = functools.partial(
        self._inverse_transform, s_net=s_net, t_net=t_net)
    z, log_p = self._right_to_left_transform(z, log_p, condition, transform)
    s_net, t_net = left_to_right
    transform = functools.partial(
        self._inverse_transform, s_net=s_net, t_net=t_net)
    z, log_p = self._left_to_right_transform(z, log_p, condition, transform)
    return z, log_p

  def _transform(self, z1, z2, log_p, condition):
    # Implement the update from the RNVP paper, using their notation. Below,
    # replace the exp(s) in the original paper with _softplus in
    # order to get more stable learning.
    zz = _add_condition(z1, condition)
    n = z2.get_shape()[1].value
    if self._hidden_size is None:
      hidden_size = n
    else:
      hidden_size = self._hidden_size
    s_net = Highway(
        output_size=n,
        hidden_size=hidden_size,
        num_blocks=self._num_layers_per_block,
        name=&#39;scale&#39;)
    t_net = Highway(
        output_size=n,
        hidden_size=hidden_size,
        num_blocks=self._num_layers_per_block,
        name=&#39;translation&#39;)
    self._layers[-1].append((s_net, t_net))
    s = s_net(zz)
    t = t_net(zz)
    scale = _MIN_SCALE + _softplus(s)
    z2_out = z2 * scale + t
    log_p_out = log_p - tf.reduce_sum(tf.log(scale), axis=-1)

    return z2_out, log_p_out

  def _inverse_transform(self, z1, z2, log_p, condition, s_net, t_net):
    zz = _add_condition(z1, condition)
    s = s_net(zz)
    t = t_net(zz)
    # The division below can lead to very large numbers if we allow the scale
    # to get very small. This effect can compound over multiple layers. That&#39;s
    # why we add _MIN_SCALE below.
    scale = _MIN_SCALE + _softplus(s)
    z2_out = (z2 - t) / scale
    log_p_out = log_p - tf.reduce_sum(tf.log(scale), axis=-1)
    return z2_out, log_p_out

  def _left_to_right_transform(self, z, log_p, condition, transform_fn):
    &#34;&#34;&#34;Affine coupling layer from the RNVP paper.&#34;&#34;&#34;
    z.get_shape().assert_has_rank(2)
    log_p.get_shape().assert_has_rank(1)
    z1, z2 = self._split(z)
    z2_out, log_p_out = transform_fn(z1, z2, log_p, condition)
    return tf.concat([z1, z2_out], axis=-1), log_p_out

  def _right_to_left_transform(self, z, log_p, condition, transform_fn):
    &#34;&#34;&#34;Affine coupling layer from the RNVP paper.&#34;&#34;&#34;
    z.get_shape().assert_has_rank(2)
    log_p.get_shape().assert_has_rank(1)
    z1, z2 = self._split(z)
    # reverse the order of z1 and z2 to get a right to left transform
    z1_out, log_p_out = transform_fn(z2, z1, log_p, condition)
    return tf.concat([z1_out, z2], axis=-1), log_p_out

  def _interlaced_transform(self, z, log_p, condition, transform_fn):
    &#34;&#34;&#34;Affine coupling layer from the RNVP paper.&#34;&#34;&#34;
    z.get_shape().assert_has_rank(2)
    log_p.get_shape().assert_has_rank(1)
    z1 = z[:, ::2]
    z2 = z[:, 1::2]
    z1_out, log_p_out = transform_fn(z2, z1, log_p, condition)
    return _interlace(z1_out, z2), log_p_out</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>sonnet.python.modules.base.AbstractModule</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="TeachMyAgent.teachers.utils.setter_solver_utils.FlatRnvp.infer"><code class="name flex">
<span>def <span class="ident">infer</span></span>(<span>self, samples, condition=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def infer(self, samples, condition=None):
  if self._layers is None:
    raise RuntimeError(
        &#39;You need to have called `sample()` at least once before calling &#39;
        &#39;`infer()`&#39;)

  return self.tf_session.run([self.infer_output, self.infer_log_p],
                             feed_dict={self._samples: samples, self._infer_condition: condition})</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.teachers.utils.setter_solver_utils.FlatRnvp.sample"><code class="name flex">
<span>def <span class="ident">sample</span></span>(<span>self, batch_size, condition=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sample(self, batch_size, condition=None):
  latent = self._random_state.normal(size=[batch_size, self._latent_size]) # mean: 0, std: 1
  return self.tf_session.run([self.sample_output, self.sample_log_p],
                             feed_dict={self._latent: latent, self._sample_condition: condition})</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.teachers.utils.setter_solver_utils.FlatRnvp.train"><code class="name flex">
<span>def <span class="ident">train</span></span>(<span>self, samples, feasibilities, returns)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train(self, samples, feasibilities, returns):
  reshaped_returns = returns.reshape((len(returns),))
  succeeded_goals = samples[reshaped_returns == 1]
  succeeded_feasibilities = feasibilities[reshaped_returns == 1]

  noise = self._random_state.uniform(low=0, high=self._loss_noise_ub, size=succeeded_goals.shape)
  noisy_succeeded_goals = succeeded_goals+noise
  if self._logit_goals:
    noisy_succeeded_goals = np.clip(noisy_succeeded_goals, 1e-4, 1 - 1e-4) # clip to match sigmoid

  latent = self.tf_session.run(self.infer_output, feed_dict={self._samples: samples, self._infer_condition:feasibilities})
  return self.tf_session.run([self._loss, self._optimizer],
                             feed_dict={
                               self._samples: noisy_succeeded_goals,
                               self._infer_condition: succeeded_feasibilities,
                               self._sample_condition: feasibilities,
                               self._latent: latent # np.clip(latent , 1e-4, 1 - 1e-4)
                             })</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="TeachMyAgent.teachers.utils.setter_solver_utils.Highway"><code class="flex name class">
<span>class <span class="ident">Highway</span></span>
<span>(</span><span>output_size, num_blocks=4, hidden_size=32, zero_init_last_layer=False, name='highway')</span>
</code></dt>
<dd>
<div class="desc"><p>A linear network with multiple highway blocks.</p>
<p>This architecture was introduced in Zilly et al, "Recurrent Highway Networks":
<a href="https://arxiv.org/abs/1607.03474">https://arxiv.org/abs/1607.03474</a></p>
<p>Constructs the network.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>output_size</code></strong></dt>
<dd>The wanted number of outputs.</dd>
<dt><strong><code>num_blocks</code></strong></dt>
<dd>The number of highway blocks.</dd>
<dt><strong><code>hidden_size</code></strong></dt>
<dd>The size on the residual connections.</dd>
<dt><strong><code>zero_init_last_layer</code></strong></dt>
<dd>Whether to initialize the last convolution with 0's.
This makes the transform an identity op in a RVNP-like architecture.
See GLOW (<a href="https://arxiv.org/abs/1807.03039">https://arxiv.org/abs/1807.03039</a>) for more details.</dd>
<dt><strong><code>name</code></strong></dt>
<dd>Name of the module.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Highway(snt.AbstractModule):
  &#34;&#34;&#34;A linear network with multiple highway blocks.

  This architecture was introduced in Zilly et al, &#34;Recurrent Highway Networks&#34;:
  https://arxiv.org/abs/1607.03474
  &#34;&#34;&#34;

  def __init__(self,
               output_size,
               num_blocks=4,
               hidden_size=32,
               zero_init_last_layer=False,
               name=&#39;highway&#39;):
    &#34;&#34;&#34;Constructs the network.

    Args:
      output_size: The wanted number of outputs.
      num_blocks: The number of highway blocks.
      hidden_size: The size on the residual connections.
      zero_init_last_layer: Whether to initialize the last convolution with 0&#39;s.
        This makes the transform an identity op in a RVNP-like architecture.
        See GLOW (https://arxiv.org/abs/1807.03039) for more details.
      name: Name of the module.
    &#34;&#34;&#34;
    super(Highway, self).__init__(name=name)
    self._output_size = output_size
    self._num_blocks = num_blocks
    self._hidden_size = hidden_size
    self._zero_init_last_layer = zero_init_last_layer

  def _build(self, inputs):
    &#34;&#34;&#34;Runs the network on the given input.

    Args:
      inputs: A `Tensor` with shape `[batch_size, hidden_size]`.

    Returns:
      A `Tensor` with shape `[batch_size, output_size]`.
    &#34;&#34;&#34;

    def _block(y):
      return _highway_block(y, hidden_size=self._hidden_size)

    y = snt.Linear(self._hidden_size)(inputs)
    # Starting with tanh.
    y = tf.tanh(y)
    for _ in range(self._num_blocks):
      y = _block(y)

    if self._zero_init_last_layer:
      final_layer_initializers = {&#39;w&#39;: tf.zeros_initializer()}
    else:
      final_layer_initializers = None

    y = snt.Linear(self._output_size, initializers=final_layer_initializers)(y)
    return y</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>sonnet.python.modules.base.AbstractModule</li>
</ul>
</dd>
<dt id="TeachMyAgent.teachers.utils.setter_solver_utils.Judge"><code class="flex name class">
<span>class <span class="ident">Judge</span></span>
<span>(</span><span>hidden_sizes, tf_session, goal_size, custom_getter=None, name='judge')</span>
</code></dt>
<dd>
<div class="desc"><p>Computes logits for probability of a goal being solvable.</p>
<p>Performs the initialisation necessary for all AbstractModule instances.</p>
<p>Every subclass of AbstractModule must begin their constructor with a call to
this constructor, i.e.</p>
<p><code>super(MySubModule, self).__init__(custom_getter=custom_getter, name=name)</code>.</p>
<p>If you instantiate sub-modules in <strong>init</strong> you must create them within the
<code>_enter_variable_scope</code> context manager to ensure they are in the module's
variable scope. Alternatively, instantiate sub-modules in <code>_build</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>_sentinel</code></strong></dt>
<dd>Variable that only carries a non-None value if <code>__init__</code> was
called without named parameters. If this is the case, a deprecation
warning is issued in form of a <code>ValueError</code>.</dd>
<dt><strong><code>custom_getter</code></strong></dt>
<dd>Callable or dictionary of callables to use as
custom getters inside the module. If a dictionary, the keys
correspond to regexes to match variable names. See the <code>tf.get_variable</code>
documentation for information about the custom_getter API.</dd>
<dt><strong><code>name</code></strong></dt>
<dd>Name of this module. Used to construct the Templated build function.
If <code>None</code> the module's class name is used (converted to snake case).</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>TypeError</code></dt>
<dd>If <code>name</code> is not a string.</dd>
<dt><code>TypeError</code></dt>
<dd>If a given <code>custom_getter</code> is not callable.</dd>
<dt><code>ValueError</code></dt>
<dd>If <code>__init__</code> was called without named arguments.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Judge(snt.AbstractModule):
  &#34;&#34;&#34;Computes logits for probability of a goal being solvable.&#34;&#34;&#34;

  def __init__(self, hidden_sizes, tf_session, goal_size, custom_getter=None, name=&#39;judge&#39;):
    super(Judge, self).__init__(custom_getter=custom_getter, name=name)
    self._layer_sizes = hidden_sizes + [1]
    self.tf_session = tf_session
    self._goal_size = goal_size
    self()
    self._loss = self._set_loss()
    self._optimizer = tf.train.AdamOptimizer(learning_rate=3e-4).minimize(self._loss)

  def _build(self):
    self._mlp = snt.nets.MLP(self._layer_sizes[1:])
    self._goal = tf.placeholder(tf.float64, shape=(None, self._goal_size))
    goal_flat = snt.BatchFlatten()(self._goal)
    self.output = self._mlp(goal_flat) # get non-activated output

  def _set_loss(self):
    self._loss_returns = tf.placeholder(tf.float64, shape=(None, 1))
    return tf.reduce_mean(
      tf.nn.sigmoid_cross_entropy_with_logits(labels=self._loss_returns, logits=self.output))

  def train(self, returns, samples):
    return self.tf_session.run([self._loss, self._optimizer],
                               feed_dict={
                                 self._loss_returns: returns,
                                 self._goal: samples
                               })

  def calculate_feasibility(self, goal):
    return self.tf_session.run(self.output, feed_dict={self._goal: goal})</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>sonnet.python.modules.base.AbstractModule</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="TeachMyAgent.teachers.utils.setter_solver_utils.Judge.calculate_feasibility"><code class="name flex">
<span>def <span class="ident">calculate_feasibility</span></span>(<span>self, goal)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_feasibility(self, goal):
  return self.tf_session.run(self.output, feed_dict={self._goal: goal})</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.teachers.utils.setter_solver_utils.Judge.train"><code class="name flex">
<span>def <span class="ident">train</span></span>(<span>self, returns, samples)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train(self, returns, samples):
  return self.tf_session.run([self._loss, self._optimizer],
                             feed_dict={
                               self._loss_returns: returns,
                               self._goal: samples
                             })</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="TeachMyAgent.teachers.utils.setter_solver_utils.NothingActivationFunction"><code class="flex name class">
<span>class <span class="ident">NothingActivationFunction</span></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class NothingActivationFunction():
  def apply(self, x):
    return x

  def inverse(self, y):
    return y

  def log_differential(self, x):
    return x</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="TeachMyAgent.teachers.utils.setter_solver_utils.NothingActivationFunction.apply"><code class="name flex">
<span>def <span class="ident">apply</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply(self, x):
  return x</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.teachers.utils.setter_solver_utils.NothingActivationFunction.inverse"><code class="name flex">
<span>def <span class="ident">inverse</span></span>(<span>self, y)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def inverse(self, y):
  return y</code></pre>
</details>
</dd>
<dt id="TeachMyAgent.teachers.utils.setter_solver_utils.NothingActivationFunction.log_differential"><code class="name flex">
<span>def <span class="ident">log_differential</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def log_differential(self, x):
  return x</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<a href="http://developmentalsystems.org/TeachMyAgent/doc/">
<img src="https://github.com/flowersteam/TeachMyAgent/blob/gh-pages/images/home/head_image.png?raw=true" style="display: block; margin: 1em auto">
</a>
<a href="http://developmentalsystems.org/TeachMyAgent/doc/">Home</a> | <a href="http://developmentalsystems.org/TeachMyAgent/">Website</a>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="TeachMyAgent.teachers.utils" href="index.html">TeachMyAgent.teachers.utils</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="TeachMyAgent.teachers.utils.setter_solver_utils.non_zero_uniform" href="#TeachMyAgent.teachers.utils.setter_solver_utils.non_zero_uniform">non_zero_uniform</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="TeachMyAgent.teachers.utils.setter_solver_utils.ClippedSigmoid" href="#TeachMyAgent.teachers.utils.setter_solver_utils.ClippedSigmoid">ClippedSigmoid</a></code></h4>
<ul class="">
<li><code><a title="TeachMyAgent.teachers.utils.setter_solver_utils.ClippedSigmoid.apply" href="#TeachMyAgent.teachers.utils.setter_solver_utils.ClippedSigmoid.apply">apply</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.setter_solver_utils.ClippedSigmoid.inverse" href="#TeachMyAgent.teachers.utils.setter_solver_utils.ClippedSigmoid.inverse">inverse</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.setter_solver_utils.ClippedSigmoid.log_differential" href="#TeachMyAgent.teachers.utils.setter_solver_utils.ClippedSigmoid.log_differential">log_differential</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="TeachMyAgent.teachers.utils.setter_solver_utils.FlatRnvp" href="#TeachMyAgent.teachers.utils.setter_solver_utils.FlatRnvp">FlatRnvp</a></code></h4>
<ul class="">
<li><code><a title="TeachMyAgent.teachers.utils.setter_solver_utils.FlatRnvp.infer" href="#TeachMyAgent.teachers.utils.setter_solver_utils.FlatRnvp.infer">infer</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.setter_solver_utils.FlatRnvp.sample" href="#TeachMyAgent.teachers.utils.setter_solver_utils.FlatRnvp.sample">sample</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.setter_solver_utils.FlatRnvp.train" href="#TeachMyAgent.teachers.utils.setter_solver_utils.FlatRnvp.train">train</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="TeachMyAgent.teachers.utils.setter_solver_utils.Highway" href="#TeachMyAgent.teachers.utils.setter_solver_utils.Highway">Highway</a></code></h4>
</li>
<li>
<h4><code><a title="TeachMyAgent.teachers.utils.setter_solver_utils.Judge" href="#TeachMyAgent.teachers.utils.setter_solver_utils.Judge">Judge</a></code></h4>
<ul class="">
<li><code><a title="TeachMyAgent.teachers.utils.setter_solver_utils.Judge.calculate_feasibility" href="#TeachMyAgent.teachers.utils.setter_solver_utils.Judge.calculate_feasibility">calculate_feasibility</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.setter_solver_utils.Judge.train" href="#TeachMyAgent.teachers.utils.setter_solver_utils.Judge.train">train</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="TeachMyAgent.teachers.utils.setter_solver_utils.NothingActivationFunction" href="#TeachMyAgent.teachers.utils.setter_solver_utils.NothingActivationFunction">NothingActivationFunction</a></code></h4>
<ul class="">
<li><code><a title="TeachMyAgent.teachers.utils.setter_solver_utils.NothingActivationFunction.apply" href="#TeachMyAgent.teachers.utils.setter_solver_utils.NothingActivationFunction.apply">apply</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.setter_solver_utils.NothingActivationFunction.inverse" href="#TeachMyAgent.teachers.utils.setter_solver_utils.NothingActivationFunction.inverse">inverse</a></code></li>
<li><code><a title="TeachMyAgent.teachers.utils.setter_solver_utils.NothingActivationFunction.log_differential" href="#TeachMyAgent.teachers.utils.setter_solver_utils.NothingActivationFunction.log_differential">log_differential</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>